{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load heart_ava.py\n",
    "import pandas as pd\n",
    "#import math\n",
    "#import scipy as sp\n",
    "import numpy as np\n",
    "#from random import shuffle\n",
    "#from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "\n",
    "def filterDataset(data):\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def train_and_test():\n",
    "    #train = False\n",
    "    #print('Reading data....')\n",
    "    data = pd.read_csv('processed.cleveland.data', names=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'], header=None)\n",
    "    #print('Removing invalid values from data....')\n",
    "    data = filterDataset(data)\n",
    "    data = data[data['num']!=0]\n",
    "    #data = data[data['num']!=4]\n",
    "    ## split data into train and test\n",
    "    cols = list(data.columns)\n",
    "    cols.remove('num')\n",
    "    target = data['num'].copy()\n",
    "    input_data = data[cols].copy()\n",
    "    dTrain, dTest, targetTrain, targetTest = train_test_split(input_data, target, test_size=0.50, stratify=target)\n",
    "    train_index = dTrain.index\n",
    "    scaler = preprocessing.StandardScaler().fit(dTrain)\n",
    "    dTrain = scaler.transform(dTrain)\n",
    "    cols = [i for i in range(dTrain.shape[1])]\n",
    "    dTrain = pd.DataFrame(dTrain, index=train_index, columns=cols)\n",
    "    labels = list(target.unique().astype(int))\n",
    "    labels.sort()\n",
    "    classes = labels.copy()\n",
    "    votes = np.zeros((dTest.shape[0], max(classes)+1), dtype=np.int)\n",
    "    clfs = []\n",
    "    while len(classes) > 1:\n",
    "        current_class = classes.pop(0)\n",
    "        for c in classes:\n",
    "            d = pd.concat([dTrain,targetTrain], axis=1, ignore_index=True)\n",
    "            d = d.reset_index(drop=True)\n",
    "            current_group = pd.concat([d[d[13]==current_class], d[d[13]==c]], axis=0, ignore_index=False)\n",
    "            y = current_group[13].copy()\n",
    "            cols = list(current_group.columns)\n",
    "            cols.remove(13)\n",
    "            x = current_group[cols].copy()\n",
    "            #print('Training model for classes ', current_class, 'and ', c, '...')\n",
    "            clf = SVC(kernel='linear').fit(x, y)\n",
    "            clfs.append(clf)\n",
    "    for clf in clfs:\n",
    "        dTest = scaler.transform(dTest)\n",
    "        cols = [i for i in range(dTest.shape[1])]\n",
    "        dTest = pd.DataFrame(dTest, columns=cols)\n",
    "        clf_pred = clf.predict(dTest)\n",
    "        for i in range(clf_pred.shape[0]):\n",
    "            votes[np.int(dTest.iloc[[i]].index[0]), np.int(clf_pred[i])] += 1\n",
    "    pred = []\n",
    "    for i in range(votes.shape[0]):\n",
    "        #pred.append(np.argmax(votes[i,:]))\n",
    "        pred.append(np.random.choice(np.where(votes[i,:] == votes[i,:].max())[0]))\n",
    "    \n",
    "    cm = confusion_matrix(targetTest, pred, labels=labels)\n",
    "    np.savetxt(\"confusion_matrix_ava.csv\", cm, delimiter=\",\")\n",
    "    score = np.sum(np.diagonal(cm))/np.sum(cm)\n",
    "    #print('score: ', score)\n",
    "    return(score)\n",
    "    \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335797101449\n",
      "0.0754195713408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in tqdm(range(100)):\n",
    "    scores.append(train_and_test())\n",
    "    \n",
    "scores = np.asarray(scores)\n",
    "print(scores.mean())\n",
    "print(scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
