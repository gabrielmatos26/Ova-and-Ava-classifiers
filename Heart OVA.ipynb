{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load heart_ova.py\n",
    "import pandas as pd\n",
    "#import math\n",
    "#import scipy as sp\n",
    "import numpy as np\n",
    "#from random import shuffle\n",
    "#from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filterDataset(data):\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test():\n",
    "    #print('Reading data....')\n",
    "    data = pd.read_csv('processed.cleveland.data', names=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'], header=None)\n",
    "    #print('Removing invalid values from data....')\n",
    "    data = filterDataset(data)\n",
    "    #print(data.shape)\n",
    "    data = data[data['num']!=0]\n",
    "    data = data[data['num']!=4]\n",
    "    #print(data.shape)\n",
    "    ## split data into train and test\n",
    "    cols = list(data.columns)\n",
    "    cols.remove('num')\n",
    "    target = data['num'].copy()\n",
    "    input_data = data[cols].copy()\n",
    "    \n",
    "    #dTrain = input_data.as_matrix()\n",
    "    #dTest = input_data.as_matrix()\n",
    "    #targetTrain = target.as_matrix()\n",
    "    #targetTest = target.as_matrix()\n",
    "    \n",
    "    #iris = datasets.load_iris()\n",
    "    #input_data = iris.data[:, :2]  # we only take the first two features.\n",
    "    #target = iris.target\n",
    "    \n",
    "    dTrain, dTest, targetTrain, targetTest = train_test_split(input_data, target, test_size=0.25, stratify=target)\n",
    "    scaler = preprocessing.StandardScaler().fit(dTrain)\n",
    "    dTrain = scaler.transform(dTrain)\n",
    "    # if train:\n",
    "    #clf = linear_model.Lasso(alpha=0.1)\n",
    "    #ovr = OneVsRestClassifier(clf)\n",
    "    ovr = svm.SVC(kernel='linear')\n",
    "    #print('Training model...')\n",
    "    #ovr.fit(dTrain, targetTrain)\n",
    "    ovr.fit(dTrain, targetTrain)\n",
    "    #     joblib.dump(ovr, 'oneVsAll.pkl')\n",
    "    #     print('Model saved!')\n",
    "    # else:\n",
    "    #     ovr = joblib.load('oneVsAll.pkl')\n",
    "    dTest = scaler.transform(dTest)\n",
    "    #pred = ovr.predict(dTest)\n",
    "    pred = ovr.predict(dTest)\n",
    "    #print(ovr.score(dTest, targetTest))\n",
    "    score = ovr.score(dTest, targetTest)\n",
    "    cm = confusion_matrix(targetTest, pred, labels=[1,2,3,4])\n",
    "    np.savetxt(\"confusion_matrix_ova.csv\", cm, delimiter=\",\")\n",
    "    return score\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.427419354839\n",
      "0.0701381125973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in tqdm(range(100)):\n",
    "    scores.append(train_and_test())\n",
    "    \n",
    "scores = np.asarray(scores)\n",
    "print(scores.mean())\n",
    "print(scores.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
