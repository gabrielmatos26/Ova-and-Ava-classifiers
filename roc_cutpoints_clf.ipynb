{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(x, min_val, max_val, k=1):\n",
    "    x0 = (min_val+max_val)/2\n",
    "    return 1/(1 + np.exp(-k*(x-x0)))\n",
    "#     return np.exp(x0+ k*x)/(1 + np.exp(x0+ k*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heart_data():\n",
    "    data = pd.read_csv('data/processed.cleveland.data', names=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'], header=None)\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def wine_quality_white():\n",
    "#     data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "    data = pd.read_csv('data/winequality-white.csv', sep=';')\n",
    "    cols = list(data.columns)\n",
    "    data[cols[-1]] -= min(data[cols[-1]])\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def wine_quality_red():\n",
    "    data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "    cols = list(data.columns)\n",
    "    data[cols[-1]] -= min(data[cols[-1]])\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def load_adult():\n",
    "    data = pd.read_csv('data/adult.data', header=None)\n",
    "    cat_columns = data.select_dtypes(['object']).columns\n",
    "    for c in cat_columns:\n",
    "        data[c] = data[c].astype('category')\n",
    "    data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def load_abalone():\n",
    "    data = pd.read_csv('data/abalone.data', header=None)\n",
    "    cat_columns = data.select_dtypes(['object']).columns\n",
    "    for c in cat_columns:\n",
    "        data[c] = data[c].astype('category')\n",
    "    data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    \n",
    "    cols = list(data.columns)\n",
    "    \n",
    "    data = data.groupby(cols[-1]).filter(lambda x: len(x) > 2)\n",
    "    data[cols[-1]] -= min(data[cols[-1]])\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "    \n",
    "\n",
    "def load_mat(mat_file):\n",
    "    data = sio.loadmat(mat_file)\n",
    "    data = np.concatenate((data['X'], data['Y']-1), axis=1)\n",
    "#     plt.scatter(data[:300,0], data[:300,1], c='c', marker='x')\n",
    "#     plt.scatter(data[300:600,0], data[300:600,1], c='b', marker='x')\n",
    "#     plt.scatter(data[900:1200,0], data[900:1200,1], c='g', marker='x')\n",
    "#     plt.scatter(data[600:900,0], data[600:900,1], c='r', marker='x')\n",
    "#     plt.scatter(data[1200:1500,0], data[1200:1500,1], c='y', marker='x')\n",
    "#     plt.scatter(data[1500:1800,0], data[1500:1800,1], c='m', marker='x')\n",
    "#     plt.scatter(data[1800:2100,0], data[1800:2100,1], c='k', marker='x')\n",
    "#     plt.scatter(data[2100:2400,0], data[2100:2400,1], marker='x')\n",
    "#     plt.show()\n",
    "    data = pd.DataFrame(data=data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#d\n",
    "def synthetic_data(p, t, n_dim=2):\n",
    "    #mean1 = np.concatenate((np.ones(1)*-10,np.ones(12)))\n",
    "    #mean2 = np.concatenate((np.ones(12),np.ones(1)*10))\n",
    "    \n",
    "    q0 = p*t\n",
    "    q1 = p*(t-q0)\n",
    "    q2 = p*(t-q0-q1)\n",
    "    q3 = p*(t-q0-q1-q2)\n",
    "    q4 = t-q0-q1-q2-q3\n",
    "    \n",
    "    q = [np.int(q0), np.int(q1), np.int(q2), np.int(q3), np.int(q4)]\n",
    "    \n",
    "#     mean0 = np.ones(n_dim)*1\n",
    "#     mean1 = np.ones(n_dim)*1.5\n",
    "#     mean2 = np.ones(n_dim)*1.7\n",
    "#     mean3 = np.ones(n_dim)*0.5\n",
    "#     mean4 = np.ones(n_dim)*1.65\n",
    "    \n",
    "    \n",
    "    mean0 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean1 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean2 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean3 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean4 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    \n",
    "    \n",
    "#     np.random.seed(1234)\n",
    "    \n",
    "    var0 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var1 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var2 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var3 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var4 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    \n",
    "    #g0 = np.random.multivariate_normal(mean0, np.eye(13), size=q[0])\n",
    "    #g1 = np.random.multivariate_normal(mean1, np.eye(13), size=q[1])\n",
    "    #g2 = np.random.multivariate_normal(mean2, np.eye(13), size=q[2])\n",
    "    #g3 = np.random.multivariate_normal(mean3, np.eye(13), size=q[3])\n",
    "    #g4 = np.random.multivariate_normal(mean4, np.eye(13), size=q[4])\n",
    "    \n",
    "    g0 = np.random.multivariate_normal(mean0, var0, size=q[0])\n",
    "    g1 = np.random.multivariate_normal(mean1, var1, size=q[1])\n",
    "    g2 = np.random.multivariate_normal(mean2, var2, size=q[2])\n",
    "    g3 = np.random.multivariate_normal(mean3, var3, size=q[3])\n",
    "    g4 = np.random.multivariate_normal(mean4, var4, size=q[4])\n",
    "\n",
    "    \n",
    "    y0 = np.asarray([0]*q[0]).reshape(q[0],1)\n",
    "    y1 = np.asarray([1]*q[1]).reshape(q[1],1)\n",
    "    y2 = np.asarray([2]*q[2]).reshape(q[2],1)\n",
    "    y3 = np.asarray([3]*q[3]).reshape(q[3],1)\n",
    "    y4 = np.asarray([4]*q[4]).reshape(q[4],1)\n",
    "\n",
    "\n",
    "    #y1 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    #y2 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    #y3 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    #y4 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    \n",
    "    g0 = np.concatenate((g0,y0), axis=1)\n",
    "    g1 = np.concatenate((g1,y1), axis=1)\n",
    "    g2 = np.concatenate((g2,y2), axis=1)\n",
    "    g3 = np.concatenate((g3,y3), axis=1)\n",
    "    g4 = np.concatenate((g4,y4), axis=1)\n",
    "\n",
    "    g = np.concatenate([g0,g1,g2,g3,g4], axis=0)\n",
    "    d = pd.DataFrame(data=g)\n",
    "\n",
    "#     d = pd.DataFrame(data=g, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "    if n_dim == 2:\n",
    "        plt.scatter(g0[:,0], g0[:,1], c='c')\n",
    "        plt.scatter(g1[:,0], g1[:,1], c='b')\n",
    "        plt.scatter(g2[:,0], g2[:,1], c='r')\n",
    "        plt.scatter(g3[:,0], g3[:,1], c='g')\n",
    "        plt.scatter(g4[:,0], g4[:,1], c='y')\n",
    "        plt.show()\n",
    "    elif n_dim == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(g0[:,0], g0[:,1], g0[:,2], c='c')\n",
    "        ax.scatter(g1[:,0], g1[:,1], g1[:,2], c='b')\n",
    "        ax.scatter(g2[:,0], g2[:,1], g2[:,2], c='r')\n",
    "        ax.scatter(g3[:,0], g3[:,1], g3[:,2], c='g')\n",
    "        ax.scatter(g4[:,0], g4[:,1], g4[:,2], c='y')\n",
    "        plt.show()\n",
    "    \n",
    "    return d\n",
    "\n",
    "#d1 = pd.DataFrame(data=g1, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "#d2 = pd.DataFrame(data=g2, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "#d3 = pd.DataFrame(data=g3, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "#d4 = pd.DataFrame(data=g4, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimal cutpoints\n",
    "\n",
    "#find the closest point to (0,1) coordinate\n",
    "def roc01(fpr, tpr):\n",
    "    tl = [0,1]\n",
    "    index = None\n",
    "    opt = np.inf\n",
    "    for i in range(len(fpr)):\n",
    "        d = np.linalg.norm(np.array(tl) - np.array([fpr[i], tpr[i]]))\n",
    "        if d < opt:\n",
    "            opt = d\n",
    "            index = i\n",
    "    return fpr[index], tpr[index]\n",
    "\n",
    "#Youden's index\n",
    "def youden_index(fpr, tpr):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt = -1\n",
    "    for i in range(len(fpr)):\n",
    "        pt = sp[i]+se[i]-1\n",
    "        if pt > opt:\n",
    "            opt = pt\n",
    "            index = i\n",
    "            \n",
    "    return fpr[index], tpr[index]\n",
    "    \n",
    "#maximize sensitivity\n",
    "def max_se(fpr, tpr, threshold=1e-4):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt_se = -1\n",
    "    opt_sp = -1\n",
    "    for i in range(len(fpr)):\n",
    "        if se[i] > opt_se:\n",
    "            opt_se = se[i]\n",
    "            opt_sp = sp[i]\n",
    "            index = i\n",
    "        elif abs(se[i]-opt_se) <= threshold:\n",
    "            if sp[i] > opt_sp:\n",
    "                opt_se = se[i]\n",
    "                opt_sp = sp[i]\n",
    "                index = i\n",
    "    return fpr[index], tpr[index]\n",
    "\n",
    "#maximize specificity\n",
    "def max_sp(fpr, tpr, threshold=1e-4):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt_se = -1\n",
    "    opt_sp = -1\n",
    "    for i in range(len(fpr)):\n",
    "        if np.isclose(fpr[i],0.0):\n",
    "            continue\n",
    "        if sp[i] > opt_sp:\n",
    "            opt_se = se[i]\n",
    "            opt_sp = sp[i]\n",
    "            index = i\n",
    "        elif abs(sp[i]-opt_sp) <= threshold:\n",
    "            if se[i] > opt_se:\n",
    "                opt_se = se[i]\n",
    "                opt_sp = sp[i]\n",
    "                index = i\n",
    "    return fpr[index], tpr[index]\n",
    "                \n",
    "## https://en.wikipedia.org/wiki/Diagnostic_odds_ratio\n",
    "def max_dor(fpr, tpr):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt_dor = -1\n",
    "    for i in range(len(fpr)):\n",
    "        dor = (se[i]/(1.0-se[i]))*(sp[i]/(1.0-sp[i]))\n",
    "        if dor > opt_dor and not np.isinf(dor) and not np.isnan(dor):\n",
    "            opt_dor = dor\n",
    "            index = i\n",
    "    return fpr[index], tpr[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ClassifierWithRoc(object):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n_classes = len(np.unique(Y))\n",
    "        self.n_clf = self.n_classes * (self.n_classes - 1) // 2\n",
    "        self.c_groups = [(t[1],t[0]) for t in list(combinations(list(range(0,self.n_classes)),2))]\n",
    "    \n",
    "    def split_data(self, X, Y, min_samples=500):\n",
    "        if X.shape[0] >= min_samples:\n",
    "            x_train, x_test_and_val, y_train, y_test_and_val = train_test_split(X, Y, test_size=.40, stratify=Y)\n",
    "            x_val, x_test, y_val, y_test = train_test_split(x_test_and_val, y_test_and_val, \n",
    "                                                            test_size=.50, stratify=y_test_and_val)\n",
    "        else:\n",
    "            x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.20, stratify=Y)\n",
    "            x_val = None; y_val = None\n",
    "            \n",
    "        return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "    \n",
    "    def z_score(self, x_train):      \n",
    "        scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "        return scaler\n",
    "    \n",
    "    def estimator(self, x_train, y_train, scaler):\n",
    "        x_train = scaler.transform(x_train)\n",
    "        ovo = OneVsOneClassifier(SVC(kernel='linear', probability=True, class_weight='balanced'), n_jobs=-1)\n",
    "        ovo.fit(x_train, y_train)\n",
    "        return ovo\n",
    "    \n",
    "    def predict(self, estimator, x_test, y_test, scaler, points=None, c=0, mode='half'):\n",
    "        modes = {'zero': 0, 'half': 0.5, 'one':1}\n",
    "        x_test = scaler.transform(x_test)\n",
    "        if points is None:\n",
    "            pred = estimator.predict(x_test)\n",
    "            cm = confusion_matrix(y_test, pred)\n",
    "            acc = cm.diagonal().sum() / cm.sum()\n",
    "            return [pred, cm, acc]\n",
    "        elif c < 2:\n",
    "            y_test_bin = label_binarize(y_test, classes=list(range(self.n_classes)))\n",
    "            votes = np.zeros(y_test_bin.shape)\n",
    "            for i in range(self.n_clf):\n",
    "                clf = estimator.estimators_[i]\n",
    "                proba = clf.decision_function(x_test)\n",
    "                for j, p in enumerate(proba):\n",
    "                    if p > points[i][c] or np.isclose(p,points[i][c]):\n",
    "                        votes[j, self.c_groups[i][0]] += 1\n",
    "                    else:\n",
    "                        votes[j, self.c_groups[i][1]] += 1\n",
    "        elif c == 2:\n",
    "            if mode != 'logistic':\n",
    "                y_test_bin = label_binarize(y_test, classes=list(range(self.n_classes)))\n",
    "                votes = np.zeros(y_test_bin.shape)\n",
    "                for i in range(self.n_clf):\n",
    "                    clf = estimator.estimators_[i]\n",
    "                    proba = clf.decision_function(x_test)\n",
    "                    for j, p in enumerate(proba):\n",
    "                        if p > points[i].max() or np.isclose(p, points[i].max()):\n",
    "                            votes[j, self.c_groups[i][0]] += 1\n",
    "                        elif p > points[i].min() and p < points[i].max():\n",
    "                            votes[j, self.c_groups[i][0]] += modes[mode]\n",
    "                            votes[j, self.c_groups[i][1]] += modes[mode]\n",
    "                        elif p < points[i].min():\n",
    "                            votes[j, self.c_groups[i][1]] += 1\n",
    "            else:\n",
    "                y_test_bin = label_binarize(y_test, classes=list(range(self.n_classes)))\n",
    "                votes = np.zeros(y_test_bin.shape)\n",
    "                for i in range(self.n_clf):\n",
    "                    clf = estimator.estimators_[i]\n",
    "                    proba = clf.decision_function(x_test)\n",
    "                    for j, p in enumerate(proba):\n",
    "                        if p > points[i].max() or np.isclose(p, points[i].max()):\n",
    "                            votes[j, self.c_groups[i][0]] += 1\n",
    "                        elif p > points[i].min() and p < points[i].max():\n",
    "                            #adjust steepness to interval\n",
    "                            #12 seeems to be a good number\n",
    "                            k = 12 / (abs(max(points[i]) - min(points[i])))\n",
    "                            point = logistic(p, min(points[i]), max(points[i]), k=k)\n",
    "                            votes[j, self.c_groups[i][0]] += point\n",
    "                            votes[j, self.c_groups[i][1]] += 1-point\n",
    "                        elif p < points[i].min():\n",
    "                            votes[j, self.c_groups[i][1]] += 1\n",
    "        \n",
    "        occurrences = np.asarray([np.where(t==t.max())[0] for t in votes])\n",
    "        pred = [p[-1] for p in occurrences]\n",
    "        cm = confusion_matrix(y_test, pred)\n",
    "        acc = cm.diagonal().sum() / cm.sum()\n",
    "        return [pred, cm, acc]\n",
    "        \n",
    "        \n",
    "    def calculate_roc(self, estimator, x_val, x_train, y_val, y_train, scaler):\n",
    "        clf_index = 0\n",
    "        fpr = dict(); tpr = dict(); thresholds = dict(); roc_auc = dict(); cutpoints = dict()\n",
    "        x_val = scaler.transform(x_val) if x_val is not None else None\n",
    "        x_train = scaler.transform(x_train)\n",
    "        y_val_bin = label_binarize(y_val, classes=list(range(self.n_classes))) if y_val is not None else None\n",
    "        y_train_bin = label_binarize(y_train, classes=list(range(self.n_classes)))\n",
    "        for i in range(self.n_classes):\n",
    "            for j in range(self.n_classes):\n",
    "                if j > i:\n",
    "                    clf = estimator.estimators_[clf_index]\n",
    "                    if y_val_bin is not None and x_val is not None:\n",
    "                        proba = clf.decision_function(x_val)\n",
    "                        fpr[clf_index], tpr[clf_index], thresholds[clf_index] = roc_curve(abs(y_val_bin[:, i]-1),\n",
    "                                                                                          proba)\n",
    "                    else:\n",
    "                        proba = clf.decision_function(x_train)\n",
    "                        fpr[clf_index], tpr[clf_index], thresholds[clf_index] = roc_curve(abs(y_train_bin[:, i]-1),\n",
    "                                                                                          proba)\n",
    "                    roc_auc[clf_index] = auc(fpr[clf_index], tpr[clf_index])\n",
    "                    youden_cut = youden_index(fpr[clf_index], tpr[clf_index])\n",
    "                    maxdor_cut = max_dor(fpr[clf_index], tpr[clf_index])\n",
    "                    y_index = np.where(np.isclose(fpr[clf_index],youden_cut[0]))[0][0]\n",
    "                    d_index = np.where(np.isclose(fpr[clf_index],maxdor_cut[0]))[0][0]\n",
    "                    if y_index == 0:\n",
    "                        y_index += 1\n",
    "                    if d_index == 0:\n",
    "                        d_index += 1\n",
    "\n",
    "                    cutpoints[clf_index] = np.array([thresholds[clf_index][y_index], thresholds[clf_index][d_index]])\n",
    "                    clf_index += 1\n",
    "        return fpr, tpr, thresholds, roc_auc, cutpoints\n",
    "    \n",
    "    def plot_roc(self, fpr, tpr, thresholds, roc_auc, cutpoints, show=True, save=False):\n",
    "        for i in range(self.n_clf):\n",
    "            youden_cut = youden_index(fpr[i], tpr[i])\n",
    "            maxdor_cut = max_dor(fpr[i], tpr[i])\n",
    "            fig, ax = plt.subplots(1,2, figsize=(15,7))\n",
    "            lw = 2\n",
    "            ax[0].plot(fpr[i], tpr[i], color='darkorange',\n",
    "                     lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[i], zorder=-1)\n",
    "            ax[0].plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', zorder=-1)\n",
    "            ax[0].set_xlim([-0.05, 1.05])\n",
    "            ax[0].set_ylim([-0.05, 1.05])\n",
    "            ax[0].set_xlabel('False Positive Rate')\n",
    "            ax[0].set_ylabel('True Positive Rate')\n",
    "            ax[0].set_title('Receiver operating characteristic for class ' + str(tuple(reversed(self.c_groups[i]))))\n",
    "            #ax.scatter(opt_cutpoint1[0], opt_cutpoint1[1], c='g', zorder=1, label='MaxSp cutpoint', s=50)\n",
    "            #ax.scatter(opt_cutpoint2[0], opt_cutpoint2[1], c='r', zorder=1, label='MaxSe cutpoint', s=50)\n",
    "            ax[0].scatter(youden_cut[0], youden_cut[1], c='b', zorder=1, label='Youden', s=50)\n",
    "            ax[0].scatter(maxdor_cut[0], maxdor_cut[1], c='r', zorder=1, label='Max Dor', s=50)\n",
    "            ax[0].legend(loc=\"lower right\")\n",
    "\n",
    "            ax2 = ax[0].twinx()\n",
    "            ax2.plot(fpr[i], thresholds[i], color='r', lw=lw, linestyle='--', zorder=-1)\n",
    "            ax2.set_ylabel('Threshold',color='r')\n",
    "            ax2.set_ylim([thresholds[i][-1],thresholds[i][0]])\n",
    "            ax2.set_xlim([-0.05, 1.05])\n",
    "\n",
    "            if np.isclose(min(cutpoints[i]), max(cutpoints[i])):  \n",
    "                ax[1].axis('off')\n",
    "            else:\n",
    "                #adjust steepness to interval\n",
    "                #12 seeems to be a good number\n",
    "                k = 12 / (abs(max(cutpoints[i]) - min(cutpoints[i])))\n",
    "\n",
    "                x_range = np.arange(min(cutpoints[i]), max(cutpoints[i]), 0.0001)\n",
    "                y_range = logistic(x_range, min(cutpoints[i]), max(cutpoints[i]), k=k)\n",
    "                ax[1].set_title('Logistic function between cutpoints')\n",
    "\n",
    "                ax[1].spines['left'].set_position('center')\n",
    "                ax[1].spines['right'].set_color('none')\n",
    "                ax[1].spines['top'].set_color('none')\n",
    "                ax[1].xaxis.set_ticks_position('bottom')\n",
    "                ax[1].yaxis.set_ticks_position('left')\n",
    "                ax[1].plot(x_range, y_range, c='y', lw=lw, zorder=-1)\n",
    "                ax[1].scatter(cutpoints[i][0], logistic(cutpoints[i][0], min(cutpoints[i]), max(cutpoints[i]), k=k), \n",
    "                              c='b', zorder=1, label='Youden', s=50)\n",
    "                ax[1].scatter(cutpoints[i][1], logistic(cutpoints[i][1], min(cutpoints[i]), max(cutpoints[i]), k=k),\n",
    "                              c='r', zorder=1, label='Max Dor', s=50)\n",
    "\n",
    "                ax[1].plot([x_range[0], x_range[0]], [-0.05, y_range[0]], linestyle='--', c='k')\n",
    "                ax[1].plot([x_range[-1], x_range[-1]], [-0.05, y_range[-1]], linestyle='--', c='k')\n",
    "                ax[1].set_xticks(cutpoints[i], minor=False)\n",
    "\n",
    "            \n",
    "            fig.subplots_adjust(hspace=0.3, wspace=0.6, top=0.8)\n",
    "            if save:\n",
    "                plots_folder = os.path.join(os.getcwd(),'roc_plots')\n",
    "                if not os.path.exists(plots_folder):\n",
    "                    os.mkdir(plots_folder)\n",
    "                plt.savefig(os.path.join(os.getcwd(), 'heart_' + str(tuple(reversed(self.c_groups[i])))) + '.png',\n",
    "                            bbox_inches='tight', pad_inches=0.5)\n",
    "            if show:\n",
    "                plt.show()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply(data, times=1):\n",
    "    cols = list(data.columns)\n",
    "    Y = data[cols[-1]].copy()\n",
    "    cols.remove(cols[-1])\n",
    "    X = data[cols].copy()\n",
    "    roc_clf = ClassifierWithRoc(X,Y)\n",
    "    \n",
    "    pred = []; pred_y = []; pred_dor = []; pred_zero = []; pred_half = []; pred_one = []; pred_log = []\n",
    "    \n",
    "    for i in tqdm(range(times)):\n",
    "        x_train, x_val, x_test, y_train, y_val, y_test = roc_clf.split_data(X, Y, min_samples=250)\n",
    "        scaler = roc_clf.z_score(x_train)\n",
    "        est = roc_clf.estimator(x_train, y_train, scaler)\n",
    "        fpr, tpr, thresholds, roc_auc, cutpoints = roc_clf.calculate_roc(est, x_val, x_train, y_val, \n",
    "                                                                         y_train, scaler)\n",
    "        pred.append(roc_clf.predict(est, x_test, y_test, scaler))\n",
    "        pred_y.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=0))\n",
    "        pred_dor.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=1))\n",
    "        pred_zero.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='zero'))\n",
    "        pred_half.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='half'))\n",
    "        pred_one.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='one'))\n",
    "        pred_log.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='logistic'))\n",
    "#         roc_clf.plot_roc(fpr, tpr, thresholds, roc_auc, cutpoints)\n",
    "    \n",
    "    pred = np.asarray(pred); pred_y = np.asarray(pred_y); pred_dor = np.asarray(pred_dor); \n",
    "    pred_zero = np.asarray(pred_zero); pred_half = np.asarray(pred_half); pred_one = np.asarray(pred_one); \n",
    "    pred_log = np.asarray(pred_log)\n",
    "    \n",
    "    return np.array([[np.mean(pred[:,2]), np.std(pred[:,2])], [np.mean(pred_y[:,2]), np.std(pred_y[:,2])], [np.mean(pred_dor[:,2]), np.std(pred_dor[:,2])],\n",
    "            [np.mean(pred_zero[:,2]), np.std(pred_zero[:,2])], [np.mean(pred_half[:,2]), np.std(pred_half[:,2])], \n",
    "            [np.mean(pred_one[:,2]), np.std(pred_one[:,2])], [np.mean(pred_log[:,2]), np.std(pred_log[:,2])]])\n",
    "\n",
    "    print(np.mean(pred[:,2]))\n",
    "    print(np.mean(pred_y[:,2]))\n",
    "    print(np.mean(pred_dor[:,2]))\n",
    "    print(np.mean(pred_zero[:,2]))\n",
    "    print(np.mean(pred_half[:,2]))\n",
    "    print(np.mean(pred_one[:,2]))\n",
    "    print(np.mean(pred_log[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.08it/s]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.52s/it]\n",
      "100%|██████████| 10/10 [01:24<00:00,  8.59s/it]\n",
      "100%|██████████| 10/10 [05:02<00:00, 30.68s/it]\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.39s/it]\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dataset             mean acc                   std  \\\n",
      "0               heart  0.47000000000000003   0.04459696053419884   \n",
      "1  white wine quality  0.43656249999999996  0.020825258851932666   \n",
      "2  white wine quality   0.3259183673469388   0.02281793284112354   \n",
      "3             abalone  0.22266187050359712    0.0126786867838462   \n",
      "4              synth8   0.7716666666666666   0.01614280885650876   \n",
      "5   unbalanced synth8   0.8717187500000001  0.010064489321992443   \n",
      "\n",
      "        mean acc yoden            std yoden     mean acc max dor  \\\n",
      "0  0.47333333333333333  0.06960204339273701   0.4633333333333334   \n",
      "1            0.1334375  0.07904520561836753  0.38156249999999997   \n",
      "2  0.21918367346938772  0.11747269215757701    0.303061224489796   \n",
      "3  0.17182254196642682  0.02348436973892947   0.1040767386091127   \n",
      "4   0.6879166666666667  0.02313907229485804   0.6472916666666666   \n",
      "5   0.8167187499999999  0.02534960629008861           0.78515625   \n",
      "\n",
      "            std max dor   mean acc both zero         std both zero  \\\n",
      "0   0.06904105059069324                0.445   0.06542595475463507   \n",
      "1   0.08285022725527069             0.388125   0.09803538901845599   \n",
      "2   0.06251696979116993   0.3185714285714286   0.09495587436173576   \n",
      "3  0.017791114619656025  0.18273381294964028  0.024333143201852897   \n",
      "4  0.029330640264633404   0.6720833333333334   0.02045913949531821   \n",
      "5   0.04622069384012425           0.81609375  0.026663869075258004   \n",
      "\n",
      "   mean acc both half         std both half   mean acc both one  \\\n",
      "0               0.495   0.06282692274990256  0.4866666666666667   \n",
      "1            0.390625   0.10308711425294628            0.381875   \n",
      "2  0.3174489795918367    0.1135219101024238  0.3314285714285715   \n",
      "3  0.1824940047961631  0.022360101104920937  0.1574340527577938   \n",
      "4  0.6979166666666666   0.02985788096224438  0.6704166666666667   \n",
      "5  0.8214062500000001  0.028675600064558385           0.8234375   \n",
      "\n",
      "           std both one mean acc both logistic     std both logistic  \n",
      "0   0.07257180352359081                   0.51  0.058309518948453015  \n",
      "1   0.09502055698637006    0.28374999999999995    0.0876650229567072  \n",
      "2   0.11482090431031669    0.24693877551020407   0.08801220050974334  \n",
      "3  0.018224236361939896    0.13501199040767387  0.012600771851721487  \n",
      "4   0.03448278556033431                0.70625   0.03627633143279818  \n",
      "5   0.02761693886910713     0.8270312499999999    0.0337373384814585  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [heart_data(), wine_quality_red(), wine_quality_white(), load_abalone(), \n",
    "            load_mat('data/synth8.mat'), load_mat('data/synth8_unbalanced.mat')]\n",
    "\n",
    "cols = ['dataset', 'mean acc', 'std', 'mean acc yoden', 'std yoden', 'mean acc max dor', 'std max dor',\n",
    "        'mean acc both zero', 'std both zero', 'mean acc both half', 'std both half',\n",
    "        'mean acc both one', 'std both one', 'mean acc both logistic', 'std both logistic']\n",
    "names = [['heart'], ['red wine quality'], ['white wine quality'], ['abalone'], ['synth8'],['unbalanced synth8']]\n",
    "\n",
    "d_rows = []\n",
    "\n",
    "times = 10\n",
    "for d in datasets:\n",
    "    d_rows.append(apply(d, times).ravel())\n",
    "d_rows = np.asarray(d_rows)\n",
    "d_rows = np.concatenate((names, d_rows), axis=1)\n",
    "df = pd.DataFrame(data=np.asarray(d_rows), columns=cols)\n",
    "print(df)\n",
    "# data = heart_data()\n",
    "# data = load_adult()\n",
    "# data = wine_quality_red()\n",
    "# data = wine_quality_white()\n",
    "# data = load_abalone()\n",
    "# data = load_mat('data/synth8.mat')\n",
    "# data = load_mat('data/synth8_unbalanced.mat')\n",
    "\n",
    "# data = heart_data()\n",
    "# apply(data).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
