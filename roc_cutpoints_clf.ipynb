{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(x, min_val, max_val, k=1):\n",
    "    x0 = (min_val+max_val)/2\n",
    "    return 1/(1 + np.exp(-k*(x-x0)))\n",
    "#     return np.exp(x0+ k*x)/(1 + np.exp(x0+ k*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heart_data():\n",
    "    data = pd.read_csv('data/processed.cleveland.data', names=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'], header=None)\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def load_car():\n",
    "    data = pd.read_csv('data/car.data', header=None)\n",
    "    cat_columns = data.select_dtypes(['object']).columns\n",
    "    for c in cat_columns:\n",
    "        data[c] = data[c].astype('category')\n",
    "    data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    \n",
    "    cols = list(data.columns)\n",
    "    \n",
    "    data = data.groupby(cols[-1]).filter(lambda x: len(x) > 2)\n",
    "    data[cols[-1]] -= min(data[cols[-1]])\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def wine_quality_white():\n",
    "#     data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "    data = pd.read_csv('data/winequality-white.csv', sep=';')\n",
    "    cols = list(data.columns)\n",
    "    data[cols[-1]] -= min(data[cols[-1]])\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def wine_quality_red():\n",
    "    data = pd.read_csv('data/winequality-red.csv', sep=';')\n",
    "    cols = list(data.columns)\n",
    "    data[cols[-1]] -= min(data[cols[-1]])\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def load_adult():\n",
    "    data = pd.read_csv('data/adult.data', header=None)\n",
    "    cat_columns = data.select_dtypes(['object']).columns\n",
    "    for c in cat_columns:\n",
    "        data[c] = data[c].astype('category')\n",
    "    data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "\n",
    "def load_abalone():\n",
    "    data = pd.read_csv('data/abalone.data', header=None)\n",
    "    cat_columns = data.select_dtypes(['object']).columns\n",
    "    for c in cat_columns:\n",
    "        data[c] = data[c].astype('category')\n",
    "    data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    \n",
    "    cols = list(data.columns)\n",
    "    \n",
    "    data = data.groupby(cols[-1]).filter(lambda x: len(x) > 2)\n",
    "    data[cols[-1]] -= min(data[cols[-1]])\n",
    "    invalidIndexes = []\n",
    "    for row in data.itertuples():\n",
    "        if '?' in row:\n",
    "            invalidIndexes.append(row[0])\n",
    "    new_data = data.drop(data.index[invalidIndexes])\n",
    "    cols = list(new_data.columns)\n",
    "    new_data[cols] = new_data[cols].astype('float32')\n",
    "    return new_data\n",
    "    \n",
    "\n",
    "def load_mat(mat_file):\n",
    "    data = sio.loadmat(mat_file)\n",
    "    data = np.concatenate((data['X'], data['Y']-1), axis=1)\n",
    "#     plt.scatter(data[:300,0], data[:300,1], c='c', marker='x')\n",
    "#     plt.scatter(data[300:600,0], data[300:600,1], c='b', marker='x')\n",
    "#     plt.scatter(data[900:1200,0], data[900:1200,1], c='g', marker='x')\n",
    "#     plt.scatter(data[600:900,0], data[600:900,1], c='r', marker='x')\n",
    "#     plt.scatter(data[1200:1500,0], data[1200:1500,1], c='y', marker='x')\n",
    "#     plt.scatter(data[1500:1800,0], data[1500:1800,1], c='m', marker='x')\n",
    "#     plt.scatter(data[1800:2100,0], data[1800:2100,1], c='k', marker='x')\n",
    "#     plt.scatter(data[2100:2400,0], data[2100:2400,1], marker='x')\n",
    "#     plt.show()\n",
    "    data = pd.DataFrame(data=data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#synthetic data\n",
    "def synthetic_data(p, t, n_dim=2):\n",
    "    #mean1 = np.concatenate((np.ones(1)*-10,np.ones(12)))\n",
    "    #mean2 = np.concatenate((np.ones(12),np.ones(1)*10))\n",
    "    \n",
    "    q0 = p*t\n",
    "    q1 = p*(t-q0)\n",
    "    q2 = p*(t-q0-q1)\n",
    "    q3 = p*(t-q0-q1-q2)\n",
    "    q4 = t-q0-q1-q2-q3\n",
    "    \n",
    "    q = [np.int(q0), np.int(q1), np.int(q2), np.int(q3), np.int(q4)]\n",
    "    \n",
    "#     mean0 = np.ones(n_dim)*1\n",
    "#     mean1 = np.ones(n_dim)*1.5\n",
    "#     mean2 = np.ones(n_dim)*1.7\n",
    "#     mean3 = np.ones(n_dim)*0.5\n",
    "#     mean4 = np.ones(n_dim)*1.65\n",
    "    \n",
    "    \n",
    "    mean0 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean1 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean2 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean3 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    mean4 = np.random.randint(1,3, size=n_dim)*np.random.rand(n_dim)\n",
    "    \n",
    "    \n",
    "#     np.random.seed(1234)\n",
    "    \n",
    "    var0 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var1 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var2 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var3 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    var4 = np.diag(np.random.randint(1,10, size=n_dim)*np.random.rand(n_dim))\n",
    "    \n",
    "    #g0 = np.random.multivariate_normal(mean0, np.eye(13), size=q[0])\n",
    "    #g1 = np.random.multivariate_normal(mean1, np.eye(13), size=q[1])\n",
    "    #g2 = np.random.multivariate_normal(mean2, np.eye(13), size=q[2])\n",
    "    #g3 = np.random.multivariate_normal(mean3, np.eye(13), size=q[3])\n",
    "    #g4 = np.random.multivariate_normal(mean4, np.eye(13), size=q[4])\n",
    "    \n",
    "    g0 = np.random.multivariate_normal(mean0, var0, size=q[0])\n",
    "    g1 = np.random.multivariate_normal(mean1, var1, size=q[1])\n",
    "    g2 = np.random.multivariate_normal(mean2, var2, size=q[2])\n",
    "    g3 = np.random.multivariate_normal(mean3, var3, size=q[3])\n",
    "    g4 = np.random.multivariate_normal(mean4, var4, size=q[4])\n",
    "\n",
    "    \n",
    "    y0 = np.asarray([0]*q[0]).reshape(q[0],1)\n",
    "    y1 = np.asarray([1]*q[1]).reshape(q[1],1)\n",
    "    y2 = np.asarray([2]*q[2]).reshape(q[2],1)\n",
    "    y3 = np.asarray([3]*q[3]).reshape(q[3],1)\n",
    "    y4 = np.asarray([4]*q[4]).reshape(q[4],1)\n",
    "\n",
    "\n",
    "    #y1 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    #y2 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    #y3 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    #y4 = np.random.choice(5, 297, p=[0.54, 0.18, 0.12, 0.12, 0.04]).reshape(297,1)\n",
    "    \n",
    "    g0 = np.concatenate((g0,y0), axis=1)\n",
    "    g1 = np.concatenate((g1,y1), axis=1)\n",
    "    g2 = np.concatenate((g2,y2), axis=1)\n",
    "    g3 = np.concatenate((g3,y3), axis=1)\n",
    "    g4 = np.concatenate((g4,y4), axis=1)\n",
    "\n",
    "    g = np.concatenate([g0,g1,g2,g3,g4], axis=0)\n",
    "    d = pd.DataFrame(data=g)\n",
    "\n",
    "#     d = pd.DataFrame(data=g, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "    if n_dim == 2:\n",
    "        plt.scatter(g0[:,0], g0[:,1], c='c')\n",
    "        plt.scatter(g1[:,0], g1[:,1], c='b')\n",
    "        plt.scatter(g2[:,0], g2[:,1], c='r')\n",
    "        plt.scatter(g3[:,0], g3[:,1], c='g')\n",
    "        plt.scatter(g4[:,0], g4[:,1], c='y')\n",
    "        plt.show()\n",
    "    elif n_dim == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(g0[:,0], g0[:,1], g0[:,2], c='c')\n",
    "        ax.scatter(g1[:,0], g1[:,1], g1[:,2], c='b')\n",
    "        ax.scatter(g2[:,0], g2[:,1], g2[:,2], c='r')\n",
    "        ax.scatter(g3[:,0], g3[:,1], g3[:,2], c='g')\n",
    "        ax.scatter(g4[:,0], g4[:,1], g4[:,2], c='y')\n",
    "        plt.show()\n",
    "    \n",
    "    return d\n",
    "\n",
    "#d1 = pd.DataFrame(data=g1, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "#d2 = pd.DataFrame(data=g2, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "#d3 = pd.DataFrame(data=g3, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n",
    "#d4 = pd.DataFrame(data=g4, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimal cutpoints\n",
    "\n",
    "#find the closest point to (0,1) coordinate\n",
    "def roc01(fpr, tpr):\n",
    "    tl = [0,1]\n",
    "    index = None\n",
    "    opt = np.inf\n",
    "    for i in range(len(fpr)):\n",
    "        d = np.linalg.norm(np.array(tl) - np.array([fpr[i], tpr[i]]))\n",
    "        if d < opt:\n",
    "            opt = d\n",
    "            index = i\n",
    "    return fpr[index], tpr[index]\n",
    "\n",
    "#Youden's index\n",
    "def youden_index(fpr, tpr):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt = -1\n",
    "    for i in range(len(fpr)):\n",
    "        pt = sp[i]+se[i]-1\n",
    "        if pt > opt:\n",
    "            opt = pt\n",
    "            index = i\n",
    "            \n",
    "    return fpr[index], tpr[index]\n",
    "    \n",
    "#maximize sensitivity\n",
    "def max_se(fpr, tpr, threshold=1e-4):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt_se = -1\n",
    "    opt_sp = -1\n",
    "    for i in range(len(fpr)):\n",
    "        if se[i] > opt_se:\n",
    "            opt_se = se[i]\n",
    "            opt_sp = sp[i]\n",
    "            index = i\n",
    "        elif abs(se[i]-opt_se) <= threshold:\n",
    "            if sp[i] > opt_sp:\n",
    "                opt_se = se[i]\n",
    "                opt_sp = sp[i]\n",
    "                index = i\n",
    "    return fpr[index], tpr[index]\n",
    "\n",
    "#maximize specificity\n",
    "def max_sp(fpr, tpr, threshold=1e-4):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt_se = -1\n",
    "    opt_sp = -1\n",
    "    for i in range(len(fpr)):\n",
    "        if np.isclose(fpr[i],0.0):\n",
    "            continue\n",
    "        if sp[i] > opt_sp:\n",
    "            opt_se = se[i]\n",
    "            opt_sp = sp[i]\n",
    "            index = i\n",
    "        elif abs(sp[i]-opt_sp) <= threshold:\n",
    "            if se[i] > opt_se:\n",
    "                opt_se = se[i]\n",
    "                opt_sp = sp[i]\n",
    "                index = i\n",
    "    return fpr[index], tpr[index]\n",
    "                \n",
    "## https://en.wikipedia.org/wiki/Diagnostic_odds_ratio\n",
    "def max_dor(fpr, tpr):\n",
    "    sp = 1-fpr\n",
    "    se = tpr\n",
    "    index = None\n",
    "    opt_dor = -1\n",
    "    for i in range(len(fpr)):\n",
    "        dor = (se[i]/(1.0-se[i]))*(sp[i]/(1.0-sp[i]))\n",
    "        if dor > opt_dor and not np.isinf(dor) and not np.isnan(dor):\n",
    "            opt_dor = dor\n",
    "            index = i\n",
    "    return fpr[index], tpr[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ClassifierWithRoc(object):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n_classes = len(np.unique(Y))\n",
    "        self.n_clf = self.n_classes * (self.n_classes - 1) // 2\n",
    "        self.c_groups = [(t[1],t[0]) for t in list(combinations(list(range(0,self.n_classes)),2))]\n",
    "    \n",
    "    def split_data(self, X, Y, min_samples=500):\n",
    "        if X.shape[0] >= min_samples:\n",
    "            x_train, x_test_and_val, y_train, y_test_and_val = train_test_split(X, Y, test_size=.40, stratify=Y)\n",
    "            x_val, x_test, y_val, y_test = train_test_split(x_test_and_val, y_test_and_val, \n",
    "                                                            test_size=.50, stratify=y_test_and_val)\n",
    "        else:\n",
    "            x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.20, stratify=Y)\n",
    "            x_val = None; y_val = None\n",
    "            \n",
    "        return np.asarray(x_train), np.asarray(x_val), np.asarray(x_test), np.asarray(y_train), np.asarray(y_val), np.asarray(y_test)\n",
    "    \n",
    "    def z_score(self, x_train):      \n",
    "        scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "        return scaler\n",
    "    \n",
    "    def estimator(self, x_train, y_train, scaler):\n",
    "        x_train = scaler.transform(x_train)\n",
    "        ovo = OneVsOneClassifier(SVC(kernel='linear', probability=True, class_weight='balanced'), n_jobs=-1)\n",
    "        ovo.fit(x_train, y_train)\n",
    "        return ovo\n",
    "    \n",
    "    def predict(self, estimator, x_test, y_test, scaler, points=None, c=0, mode='half', clfs=None):\n",
    "        modes = {'zero': 0, 'half': 0.5, 'one':1}\n",
    "        x_test = scaler.transform(x_test)\n",
    "        if points is None:\n",
    "            y_test_bin = label_binarize(y_test, classes=list(range(self.n_classes)))\n",
    "            votes = np.zeros(y_test_bin.shape)\n",
    "#             pred = estimator.predict(x_test)\n",
    "            if clfs is None:\n",
    "                for i in range(self.n_clf):\n",
    "                    clf = estimator.estimators_[i]\n",
    "                    proba = clf.decision_function(x_test)\n",
    "                    for j, p in enumerate(proba):\n",
    "                        if p > 0:\n",
    "                            votes[j, self.c_groups[i][0]] += 1\n",
    "                        else:\n",
    "                            votes[j, self.c_groups[i][1]] += 1\n",
    "            else:\n",
    "                for i in clfs:\n",
    "                    clf = estimator.estimators_[i]\n",
    "                    proba = clf.decision_function(x_test)\n",
    "                    for j, p in enumerate(proba):\n",
    "                        if p > 0:\n",
    "                            votes[j, self.c_groups[i][0]] += 1\n",
    "                        else:\n",
    "                            votes[j, self.c_groups[i][1]] += 1\n",
    "#             cm = confusion_matrix(y_test, pred)\n",
    "#             acc = cm.diagonal().sum() / cm.sum()\n",
    "#             return [pred, cm, acc]\n",
    "        elif c < 2:\n",
    "            y_test_bin = label_binarize(y_test, classes=list(range(self.n_classes)))\n",
    "            votes = np.zeros(y_test_bin.shape)\n",
    "            if clfs is None:\n",
    "                for i in range(self.n_clf):\n",
    "                    clf = estimator.estimators_[i]\n",
    "                    proba = clf.decision_function(x_test)\n",
    "                    for j, p in enumerate(proba):\n",
    "                        if p > points[i][c] or np.isclose(p,points[i][c]):\n",
    "                            votes[j, self.c_groups[i][0]] += 1\n",
    "                        else:\n",
    "                            votes[j, self.c_groups[i][1]] += 1\n",
    "            else:\n",
    "                for i in clfs:\n",
    "                    clf = estimator.estimators_[i]\n",
    "                    proba = clf.decision_function(x_test)\n",
    "                    for j, p in enumerate(proba):\n",
    "                        if p > points[i][c] or np.isclose(p,points[i][c]):\n",
    "                            votes[j, self.c_groups[i][0]] += 1\n",
    "                        else:\n",
    "                            votes[j, self.c_groups[i][1]] += 1\n",
    "        elif c == 2:\n",
    "            if mode != 'logistic':\n",
    "                y_test_bin = label_binarize(y_test, classes=list(range(self.n_classes)))\n",
    "                votes = np.zeros(y_test_bin.shape)\n",
    "                if clfs is None:\n",
    "                    for i in range(self.n_clf):\n",
    "                        clf = estimator.estimators_[i]\n",
    "                        proba = clf.decision_function(x_test)\n",
    "                        for j, p in enumerate(proba):\n",
    "                            if p > points[i].max() or np.isclose(p, points[i].max()):\n",
    "                                votes[j, self.c_groups[i][0]] += 1\n",
    "                            elif p > points[i].min() and p < points[i].max():\n",
    "                                votes[j, self.c_groups[i][0]] += modes[mode]\n",
    "                                votes[j, self.c_groups[i][1]] += modes[mode]\n",
    "                            elif p < points[i].min():\n",
    "                                votes[j, self.c_groups[i][1]] += 1\n",
    "                else:\n",
    "                    for i in clfs:\n",
    "                        clf = estimator.estimators_[i]\n",
    "                        proba = clf.decision_function(x_test)\n",
    "                        for j, p in enumerate(proba):\n",
    "                            if p > points[i].max() or np.isclose(p, points[i].max()):\n",
    "                                votes[j, self.c_groups[i][0]] += 1\n",
    "                            elif p > points[i].min() and p < points[i].max():\n",
    "                                votes[j, self.c_groups[i][0]] += modes[mode]\n",
    "                                votes[j, self.c_groups[i][1]] += modes[mode]\n",
    "                            elif p < points[i].min():\n",
    "                                votes[j, self.c_groups[i][1]] += 1\n",
    "            else:\n",
    "                y_test_bin = label_binarize(y_test, classes=list(range(self.n_classes)))\n",
    "                votes = np.zeros(y_test_bin.shape)\n",
    "                if clfs is None:\n",
    "                    for i in range(self.n_clf):\n",
    "                        clf = estimator.estimators_[i]\n",
    "                        proba = clf.decision_function(x_test)\n",
    "                        for j, p in enumerate(proba):\n",
    "                            if p > points[i].max() or np.isclose(p, points[i].max()):\n",
    "                                votes[j, self.c_groups[i][0]] += 1\n",
    "                            elif p > points[i].min() and p < points[i].max():\n",
    "                                #adjust steepness to interval\n",
    "                                #12 seeems to be a good number\n",
    "                                k = 12 / (abs(max(points[i]) - min(points[i])))\n",
    "                                point = logistic(p, min(points[i]), max(points[i]), k=k)\n",
    "                                votes[j, self.c_groups[i][0]] += point\n",
    "                                votes[j, self.c_groups[i][1]] += 1-point\n",
    "                            elif p < points[i].min():\n",
    "                                votes[j, self.c_groups[i][1]] += 1\n",
    "                else:\n",
    "                    for i in clfs:\n",
    "                        clf = estimator.estimators_[i]\n",
    "                        proba = clf.decision_function(x_test)\n",
    "                        for j, p in enumerate(proba):\n",
    "                            if p > points[i].max() or np.isclose(p, points[i].max()):\n",
    "                                votes[j, self.c_groups[i][0]] += 1\n",
    "                            elif p > points[i].min() and p < points[i].max():\n",
    "                                #adjust steepness to interval\n",
    "                                #12 seeems to be a good number\n",
    "                                k = 12 / (abs(max(points[i]) - min(points[i])))\n",
    "                                point = logistic(p, min(points[i]), max(points[i]), k=k)\n",
    "                                votes[j, self.c_groups[i][0]] += point\n",
    "                                votes[j, self.c_groups[i][1]] += 1-point\n",
    "                            elif p < points[i].min():\n",
    "                                votes[j, self.c_groups[i][1]] += 1\n",
    "        \n",
    "#         print(votes)\n",
    "        occurrences = np.asarray([np.where(t==t.max())[0] for t in votes])\n",
    "#         print(occurrences)\n",
    "        pred = [p[-1] for p in occurrences]\n",
    "        cm = confusion_matrix(y_test, pred)\n",
    "        acc = cm.diagonal().sum() / cm.sum()\n",
    "        return [pred, cm, acc]\n",
    "        \n",
    "        \n",
    "    def calculate_roc(self, estimator, x_val, x_train, y_val, y_train, scaler):\n",
    "        clf_index = 0\n",
    "        fpr = dict(); tpr = dict(); thresholds = dict(); roc_auc = dict(); cutpoints = dict()\n",
    "        x_val = scaler.transform(x_val) if x_val is not None else None\n",
    "        x_train = scaler.transform(x_train)\n",
    "        y_val_bin = label_binarize(y_val, classes=list(range(self.n_classes))) if y_val is not None else None\n",
    "        y_train_bin = label_binarize(y_train, classes=list(range(self.n_classes)))\n",
    "        for i in range(self.n_classes):\n",
    "            for j in range(self.n_classes):\n",
    "                if j > i:\n",
    "                    clf = estimator.estimators_[clf_index]\n",
    "                    if y_val_bin is not None and x_val is not None:\n",
    "                        proba = clf.decision_function(x_val)\n",
    "                        fpr[clf_index], tpr[clf_index], thresholds[clf_index] = roc_curve(abs(y_val_bin[:, i]-1),\n",
    "                                                                                          proba)\n",
    "                    else:\n",
    "                        proba = clf.decision_function(x_train)\n",
    "                        fpr[clf_index], tpr[clf_index], thresholds[clf_index] = roc_curve(abs(y_train_bin[:, i]-1),\n",
    "                                                                                          proba)\n",
    "                    roc_auc[clf_index] = auc(fpr[clf_index], tpr[clf_index])\n",
    "                    youden_cut = youden_index(fpr[clf_index], tpr[clf_index])\n",
    "                    maxdor_cut = max_dor(fpr[clf_index], tpr[clf_index])\n",
    "                    y_index = np.where(np.isclose(fpr[clf_index],youden_cut[0]))[0][0]\n",
    "                    d_index = np.where(np.isclose(fpr[clf_index],maxdor_cut[0]))[0][0]\n",
    "                    if y_index == 0:\n",
    "                        y_index += 1\n",
    "                    if d_index == 0:\n",
    "                        d_index += 1\n",
    "\n",
    "                    cutpoints[clf_index] = np.array([thresholds[clf_index][y_index], thresholds[clf_index][d_index]])\n",
    "                    clf_index += 1\n",
    "        return fpr, tpr, thresholds, roc_auc, cutpoints\n",
    "    \n",
    "    def plot_roc(self, fpr, tpr, thresholds, roc_auc, cutpoints, show=True, save=False, clfs=None):\n",
    "        range_clf = list(range(self.n_clf)) if clfs is None else clfs\n",
    "        for i in range_clf:\n",
    "            youden_cut = youden_index(fpr[i], tpr[i])\n",
    "            maxdor_cut = max_dor(fpr[i], tpr[i])\n",
    "            default = np.where(np.isclose(thresholds[i],min(thresholds[i], key=abs)))[0][0]\n",
    "            fig, ax = plt.subplots(1,2, figsize=(15,7))\n",
    "            lw = 2\n",
    "            ax[0].plot(fpr[i], tpr[i], color='darkorange',\n",
    "                     lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[i], zorder=-1)\n",
    "            ax[0].plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', zorder=-1)\n",
    "            ax[0].set_xlim([-0.05, 1.05])\n",
    "            ax[0].set_ylim([-0.05, 1.05])\n",
    "            ax[0].set_xlabel('False Positive Rate')\n",
    "            ax[0].set_ylabel('True Positive Rate')\n",
    "            ax[0].set_title('Receiver operating characteristic for class ' + str(tuple(reversed(self.c_groups[i]))))\n",
    "            #ax.scatter(opt_cutpoint1[0], opt_cutpoint1[1], c='g', zorder=1, label='MaxSp cutpoint', s=50)\n",
    "            #ax.scatter(opt_cutpoint2[0], opt_cutpoint2[1], c='r', zorder=1, label='MaxSe cutpoint', s=50)\n",
    "            ax[0].scatter(youden_cut[0], youden_cut[1], c='b', zorder=1, label='Youden', s=50)\n",
    "            ax[0].scatter(maxdor_cut[0], maxdor_cut[1], c='r', zorder=1, label='Max Dor', s=50)\n",
    "            ax[0].scatter(fpr[i][default], tpr[i][default], c='g', zorder=1, label='Default', s=50)\n",
    "            ax[0].legend(loc=\"lower right\")\n",
    "\n",
    "            ax2 = ax[0].twinx()\n",
    "            ax2.plot(fpr[i], thresholds[i], color='r', lw=lw, linestyle='--', zorder=-1)\n",
    "            ax2.set_ylabel('Threshold',color='r')\n",
    "            ax2.set_ylim([thresholds[i][-1],thresholds[i][0]])\n",
    "            ax2.set_xlim([-0.05, 1.05])\n",
    "\n",
    "            if np.isclose(min(cutpoints[i]), max(cutpoints[i])):  \n",
    "                ax[1].axis('off')\n",
    "            else:\n",
    "                #adjust steepness to interval\n",
    "                #12 seeems to be a good number\n",
    "                k = 12 / (abs(max(cutpoints[i]) - min(cutpoints[i])))\n",
    "\n",
    "                x_range = np.arange(min(cutpoints[i]), max(cutpoints[i]), 0.0001)\n",
    "                y_range = logistic(x_range, min(cutpoints[i]), max(cutpoints[i]), k=k)\n",
    "                ax[1].set_title('Logistic function between cutpoints')\n",
    "\n",
    "                ax[1].spines['left'].set_position('center')\n",
    "                ax[1].spines['right'].set_color('none')\n",
    "                ax[1].spines['top'].set_color('none')\n",
    "                ax[1].xaxis.set_ticks_position('bottom')\n",
    "                ax[1].yaxis.set_ticks_position('left')\n",
    "                ax[1].plot(x_range, y_range, c='y', lw=lw, zorder=-1)\n",
    "                ax[1].scatter(cutpoints[i][0], logistic(cutpoints[i][0], min(cutpoints[i]), max(cutpoints[i]), k=k), \n",
    "                              c='b', zorder=1, label='Youden', s=50)\n",
    "                ax[1].scatter(cutpoints[i][1], logistic(cutpoints[i][1], min(cutpoints[i]), max(cutpoints[i]), k=k),\n",
    "                              c='r', zorder=1, label='Max Dor', s=50)\n",
    "\n",
    "                ax[1].plot([x_range[0], x_range[0]], [-0.05, y_range[0]], linestyle='--', c='k')\n",
    "                ax[1].plot([x_range[-1], x_range[-1]], [-0.05, y_range[-1]], linestyle='--', c='k')\n",
    "                ax[1].set_xticks(cutpoints[i], minor=False)\n",
    "\n",
    "            \n",
    "            fig.subplots_adjust(hspace=0.3, wspace=0.6, top=0.8)\n",
    "            if save:\n",
    "                plots_folder = os.path.join(os.getcwd(),'roc_plots')\n",
    "                if not os.path.exists(plots_folder):\n",
    "                    os.mkdir(plots_folder)\n",
    "                plt.savefig(os.path.join(os.getcwd(), 'heart_' + str(tuple(reversed(self.c_groups[i])))) + '.png',\n",
    "                            bbox_inches='tight', pad_inches=0.5)\n",
    "            if show:\n",
    "                plt.show()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply(data, times=1, clfs=None):\n",
    "    cols = list(data.columns)\n",
    "    Y = data[cols[-1]].copy()\n",
    "    cols.remove(cols[-1])\n",
    "    X = data[cols].copy()\n",
    "    roc_clf = ClassifierWithRoc(X,Y)\n",
    "    \n",
    "    pred = []; pred_y = []; pred_dor = []; pred_zero = []; pred_half = []; pred_one = []; pred_log = []\n",
    "    \n",
    "    for i in tqdm(range(times)):\n",
    "        x_train, x_val, x_test, y_train, y_val, y_test = roc_clf.split_data(X, Y)\n",
    "        scaler = roc_clf.z_score(x_train)\n",
    "        est = roc_clf.estimator(x_train, y_train, scaler)\n",
    "        fpr, tpr, thresholds, roc_auc, cutpoints = roc_clf.calculate_roc(est, x_val, x_train, y_val, \n",
    "                                                                         y_train, scaler)\n",
    "        pred.append(roc_clf.predict(est, x_test, y_test, scaler, clfs=clfs))\n",
    "        pred_y.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=0, clfs=clfs))\n",
    "        pred_dor.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=1, clfs=clfs))\n",
    "        pred_zero.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='zero', clfs=clfs))\n",
    "        pred_half.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='half', clfs=clfs))\n",
    "        pred_one.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='one', clfs=clfs))\n",
    "        pred_log.append(roc_clf.predict(est, x_test, y_test, scaler, cutpoints, c=2, mode='logistic', clfs=clfs))\n",
    "#         roc_clf.plot_roc(fpr, tpr, thresholds, roc_auc, cutpoints)\n",
    "    \n",
    "    pred = np.asarray(pred); pred_y = np.asarray(pred_y); pred_dor = np.asarray(pred_dor); \n",
    "    pred_zero = np.asarray(pred_zero); pred_half = np.asarray(pred_half); pred_one = np.asarray(pred_one); \n",
    "    pred_log = np.asarray(pred_log)\n",
    "    \n",
    "    return np.array([[np.mean(pred[:,2]), np.std(pred[:,2])], [np.mean(pred_y[:,2]), np.std(pred_y[:,2])], [np.mean(pred_dor[:,2]), np.std(pred_dor[:,2])],\n",
    "            [np.mean(pred_zero[:,2]), np.std(pred_zero[:,2])], [np.mean(pred_half[:,2]), np.std(pred_half[:,2])], \n",
    "            [np.mean(pred_one[:,2]), np.std(pred_one[:,2])], [np.mean(pred_log[:,2]), np.std(pred_log[:,2])]])\n",
    "\n",
    "#     print(np.mean(pred[:,2]))\n",
    "#     print(np.mean(pred_y[:,2]))\n",
    "#     print(np.mean(pred_dor[:,2]))\n",
    "#     print(np.mean(pred_zero[:,2]))\n",
    "#     print(np.mean(pred_half[:,2]))\n",
    "#     print(np.mean(pred_one[:,2]))\n",
    "#     print(np.mean(pred_log[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (4, 0), (5, 0), (4, 1), (5, 1), (5, 4)] 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75b1af8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7] [7, 6] [6, 7, 0] [6, 7, 0] [1, 0, 5] [6, 7] [7, 6] [2, 3] [0, 1]\n",
      " [7, 6] [1, 5, 0, 4] [6, 7] [2, 3] [4, 5] [4, 5, 1] [4, 5] [7, 6] [0, 1]\n",
      " [3, 2] [1, 0, 5] [6, 7] [1, 5, 0] [3, 2] [4, 5] [4, 5] [2, 3] [2, 3]\n",
      " [0, 1] [0, 1] [6, 7] [7, 6, 0] [3, 2] [5, 1, 4, 0] [3, 2, 6] [1, 5, 0, 4]\n",
      " [6, 7] [5, 1, 4] [0, 1, 5] [2, 3] [0, 1] [1, 0, 5] [3, 2] [1, 5, 0, 4]\n",
      " [7, 6] [3, 2] [1, 0, 5] [7, 6] [5, 4, 1] [0, 1] [3, 2] [6, 7] [6, 7]\n",
      " [7, 0, 6, 1] [7, 6, 0] [5, 4, 1] [2, 3] [3, 2] [4, 5, 1] [1, 5, 0, 4]\n",
      " [1, 5, 0, 4] [4, 5] [0, 1] [4, 5] [3, 2] [2, 3] [7, 6] [2, 3] [1, 0, 5]\n",
      " [4, 5, 1] [1, 0, 5] [5, 4, 1] [4, 5, 1] [6, 7] [6, 7] [2, 3] [2, 3] [2, 3]\n",
      " [6, 7] [7, 6] [6, 7, 0, 1] [7, 6] [4, 5] [4, 5] [3, 2] [6, 7, 0, 1] [4, 5]\n",
      " [0, 1] [7, 6] [2, 3] [7, 6] [2, 3] [5, 4, 1] [6, 7, 0] [0, 1] [3, 2]\n",
      " [3, 2] [3, 2] [6, 7] [2, 3] [3, 2]]\n"
     ]
    }
   ],
   "source": [
    "data = load_mat('data/synth8.mat')\n",
    "c1, c2, c3, c4, c5 = data[:300], data[300:600], data[600:900], data[900:1200], data[1200:1500], \n",
    "c6, c7, c8 = data[1500:1800], data[1800:2100], data[2100:2400]\n",
    "\n",
    "classes = np.array([[c1,'c','x'], [c2,'b','+'], [c3,'r','*'], [c4,'g','^'], [c5,'y','D'], \n",
    "           [c6,'m','o'], [c7,'k','<'], [c8,(31/255, 119/255, 180/255),'>']])\n",
    "\n",
    "centroid1, centroid2, centroid3, centroid4 = np.mean(c1, axis=0)[:2], np.mean(c2, axis=0)[:2], np.mean(c3, axis=0)[:2], np.mean(c4, axis=0)[:2]\n",
    "centroid5, centroid6, centroid7, centroid8 = np.mean(c5, axis=0)[:2], np.mean(c6, axis=0)[:2], np.mean(c7, axis=0)[:2], np.mean(c8, axis=0)[:2]\n",
    "\n",
    "centroids = np.array([centroid1, centroid2, centroid3, centroid4, centroid5, centroid6, centroid7, centroid8])\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()\n",
    "for i, c in enumerate(classes):\n",
    "    plt.scatter(c[0][0], c[0][1], c=c[1], marker=c[2], label=str(i), alpha=0.2)\n",
    "    plt.scatter(centroids[i][0], centroids[i][1], c=(0.5,0.5,0.5), marker='o', s=60)\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "#test points\n",
    "\n",
    "# p = np.array([[-1, 6, ]])\n",
    "# p = np.array([[-1, 6]])\n",
    "# p = np.array([[2, 0.5]])\n",
    "# p = np.array([[3.5, 5.8]])\n",
    "# p = np.array([[2.5, -5]])\n",
    "# p_class = 1\n",
    "\n",
    "# d1, d2, d3 = np.linalg.norm(p[0]-centroid1), np.linalg.norm(p[0]-centroid2), np.linalg.norm(p[0]-centroid3)\n",
    "# d4, d5, d6 = np.linalg.norm(p[0]-centroid4), np.linalg.norm(p[0]-centroid5), np.linalg.norm(p[0]-centroid6)\n",
    "# d7, d8 = np.linalg.norm(p[0]-centroid7), np.linalg.norm(p[0]-centroid8)\n",
    "\n",
    "# dists = [[d1,0],[d2,1],[d3,2],[d4,3],[d5,4],[d6,5],[d7,6],[d8,7]]\n",
    "# dists.sort()\n",
    "# print(dists[:int(len(dists)/2)])\n",
    "# chosen = np.asarray(dists[:int(len(dists)/2)])[:,1]\n",
    "# print(chosen)\n",
    "\n",
    "\n",
    "# plt.scatter(p[0,0], p[0,1], c=(0.2,0.8,0.2), marker='^', s=100)\n",
    "\n",
    "# np.random.seed(1)\n",
    "\n",
    "\n",
    "cols = list(data.columns)\n",
    "Y = data[cols[-1]].copy()\n",
    "cols.remove(cols[-1])\n",
    "X = data[cols].copy()\n",
    "roc_clf = ClassifierWithRoc(X,Y)\n",
    "# print(roc_clf.c_groups, len(roc_clf.c_groups))\n",
    "pairs = [pair for pair in roc_clf.c_groups if pair[0] in chosen and pair[1] in chosen]\n",
    "clfs = [roc_clf.c_groups.index(clf) for clf in pairs]\n",
    "print(pairs, len(pairs))\n",
    "# print(clfs)\n",
    "\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = roc_clf.split_data(X, Y)\n",
    "scaler = roc_clf.z_score(x_train)\n",
    "est = roc_clf.estimator(x_train, y_train, scaler)\n",
    "fpr, tpr, thresholds, roc_auc, cutpoints = roc_clf.calculate_roc(est, x_val, x_train, y_val, \n",
    "                                                                 y_train, scaler)\n",
    "\n",
    "x_test, y_test = np.asarray(x_test), np.asarray(y_test)\n",
    "test_indexes = np.random.randint(len(x_test), size=100)\n",
    "p_test = x_test[test_indexes]\n",
    "c_test = y_test[test_indexes]\n",
    "\n",
    "# p_test = x_test\n",
    "# c_test = y_test\n",
    "\n",
    "#calculate distances\n",
    "distances = []\n",
    "for i, pt in enumerate(p_test):\n",
    "    plt.scatter(pt[0], pt[1], c=(0.2,0.8,0.2), marker='v', s=100)\n",
    "    plt.annotate(str(i), xy=(pt[0], pt[1]), xytext=(-5, 5), \n",
    "                 textcoords='offset points', ha='right', va='bottom', bbox=dict(boxstyle='round,pad=0.5', \n",
    "                                                                                fc='yellow', alpha=0.8))\n",
    "    dist = []\n",
    "    for j, c in enumerate(centroids):\n",
    "        d = np.linalg.norm(pt-c)\n",
    "        dist.append([d, j])\n",
    "    dist.sort()\n",
    "    distances.append(dist)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "distances = np.asarray(distances)\n",
    "\n",
    "c_distances = []\n",
    "\n",
    "for dist in distances:\n",
    "    c_dist = []\n",
    "    for i, d in enumerate(dist):\n",
    "        if i == 0:\n",
    "            c_dist.append([0.0, d[1]])\n",
    "            continue\n",
    "        else:\n",
    "            c_dist.append([d[0]-dist[0,0], d[1]])\n",
    "    c_distances.append(c_dist)\n",
    "\n",
    "c_distances = np.asarray(c_distances)\n",
    "\n",
    "influences = []\n",
    "for i, dist in enumerate(c_distances):    \n",
    "    std = np.std(dist[:,0])\n",
    "    influences.append(list(dist[np.where(dist[:,0] < std)[0]][:,1].astype(np.int32)))\n",
    "#     plt.title(\"Point \" + str(i))\n",
    "# #     print(dist)\n",
    "#     x_axis = np.arange(len(dist))\n",
    "#     plt.plot(x_axis, dist[:,0])\n",
    "#     plt.scatter(x_axis, dist[:,0])\n",
    "#     for j, d in enumerate(dist):\n",
    "#         plt.annotate(d[1], xy=(x_axis[j], d[0]), ha='right', va='bottom')\n",
    "#     plt.yticks(dist[:,0])\n",
    "#     plt.show()\n",
    "    \n",
    "influences = np.asarray(influences)\n",
    "# print(c_test)\n",
    "\n",
    "print(influences)\n",
    "# influences = np.array([[0,1,6,7],[4,5], [4,5], [0,1,6,7], [3,4,5], [0,1,3,6,7], [3,6,7], [2,3], \n",
    "#                        [0,4,5], [2,3]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 10/10 [00:35<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------------+-----------------------+\n",
      "| With all clf mean | With all clf std | With filtered clf mean | With filtered clf std |\n",
      "+-------------------+------------------+------------------------+-----------------------+\n",
      "|       0.765       | 0.0478016736109  |         0.761          |     0.044821869662    |\n",
      "|       0.688       | 0.0331058907145  |         0.641          |    0.0410974451761    |\n",
      "|       0.641       | 0.0533760245803  |         0.623          |    0.0562227711875    |\n",
      "|       0.672       | 0.0526877594893  |         0.604          |    0.0708801805867    |\n",
      "|       0.691       | 0.0406078810085  |         0.654          |    0.0557135531087    |\n",
      "|        0.68       | 0.0495983870705  |         0.653          |     0.051778373864    |\n",
      "|       0.722       |  0.033406586177  |         0.689          |    0.0385875627631    |\n",
      "+-------------------+------------------+------------------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()\n",
    "# for j, p in enumerate(p_test):\n",
    "#     plt.annotate('Point ' + str(j), xy=(p[0], p[1]), ha='left', va='top')\n",
    "#     for i in influences[j]:\n",
    "#         plt.plot([p[0], centroids[i,0]], [p[1], centroids[i,1]], '-o', color=classes[i,1])\n",
    "#     plt.title(\"Influence graph for point \" + str(j))\n",
    "#     plt.xticks(np.arange(min(x_train[:,0]), max(x_train[:,0])))\n",
    "#     plt.yticks(np.arange(min(x_train[:,1]), max(x_train[:,1])))\n",
    "#     plt.show()\n",
    "\n",
    "times = 10\n",
    "\n",
    "acc_clf_pred = []; acc_clf_pred_y = []; acc_clf_pred_dor = []; acc_clf_pred_zero = []; acc_clf_pred_half = [];\n",
    "acc_clf_pred_one = []; acc_clf_pred_log = []\n",
    "\n",
    "acc_all_pred = []; acc_all_pred_y = []; acc_all_pred_dor = []; acc_all_pred_zero = []; acc_all_pred_half = [];\n",
    "acc_all_pred_one = []; acc_all_pred_log = []\n",
    "\n",
    "for t in tqdm(range(times)):\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = roc_clf.split_data(X, Y)\n",
    "    scaler = roc_clf.z_score(x_train)\n",
    "    est = roc_clf.estimator(x_train, y_train, scaler)\n",
    "    fpr, tpr, thresholds, roc_auc, cutpoints = roc_clf.calculate_roc(est, x_val, x_train, y_val, \n",
    "                                                                     y_train, scaler)\n",
    "\n",
    "    x_test, y_test = np.asarray(x_test), np.asarray(y_test)\n",
    "    test_indexes = np.random.randint(len(x_test), size=100)\n",
    "    p_test = x_test[test_indexes]\n",
    "    c_test = y_test[test_indexes]\n",
    "    \n",
    "    #calculate distances\n",
    "    distances = []\n",
    "    for i, pt in enumerate(p_test):\n",
    "        dist = []\n",
    "        for j, c in enumerate(centroids):\n",
    "            d = np.linalg.norm(pt-c)\n",
    "            dist.append([d, j])\n",
    "        dist.sort()\n",
    "        distances.append(dist)\n",
    "\n",
    "    distances = np.asarray(distances)\n",
    "\n",
    "    c_distances = []\n",
    "\n",
    "    for dist in distances:\n",
    "        c_dist = []\n",
    "        for i, d in enumerate(dist):\n",
    "            if i == 0:\n",
    "                c_dist.append([0.0, d[1]])\n",
    "                continue\n",
    "            else:\n",
    "                c_dist.append([d[0]-dist[0,0], d[1]])\n",
    "        c_distances.append(c_dist)\n",
    "\n",
    "    c_distances = np.asarray(c_distances)\n",
    "\n",
    "    influences = []\n",
    "    for i, dist in enumerate(c_distances):    \n",
    "        std = np.std(dist[:,0])\n",
    "        influences.append(list(dist[np.where(dist[:,0] < std)[0]][:,1].astype(np.int32)))\n",
    "\n",
    "    influences = np.asarray(influences)\n",
    "    \n",
    "    t_1 = PrettyTable(['point', 'original', 'default', 'youden', 'max dor', 'both zero', 'both half', 'both one', 'both logistic'])\n",
    "\n",
    "    clf_pred = []; clf_pred_y = []; clf_pred_dor = []; clf_pred_zero = []; clf_pred_half = []; clf_pred_one = []; \n",
    "    clf_pred_log = []\n",
    "\n",
    "    for i, inf in enumerate(influences):  \n",
    "        pairs = [pair for pair in roc_clf.c_groups if pair[0] in inf and pair[1] in inf]\n",
    "        clfs = [roc_clf.c_groups.index(clf) for clf in pairs]\n",
    "        pred = roc_clf.predict(est, np.array([p_test[i]]), np.array([c_test[i]]), scaler, clfs=clfs)\n",
    "        pred_y = roc_clf.predict(est, np.array([p_test[i]]), np.array([c_test[i]]), scaler, cutpoints, c=0, clfs=clfs)\n",
    "        pred_dor = roc_clf.predict(est, np.array([p_test[i]]), np.array([c_test[i]]), scaler, cutpoints, c=1, clfs=clfs)\n",
    "        pred_zero = roc_clf.predict(est, np.array([p_test[i]]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='zero', clfs=clfs)\n",
    "        pred_half = roc_clf.predict(est, np.array([p_test[i]]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='half', clfs=clfs)\n",
    "        pred_one = roc_clf.predict(est, np.array([p_test[i]]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='one', clfs=clfs)\n",
    "        pred_log = roc_clf.predict(est, np.array([p_test[i]]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='logistic', clfs=clfs)\n",
    "\n",
    "\n",
    "        clf_pred.append(pred[0]); clf_pred_y.append(pred_y[0]); clf_pred_dor.append(pred_dor[0]); clf_pred_zero.append(pred_zero[0]);\n",
    "        clf_pred_half.append(pred_half[0]); clf_pred_one.append(pred_one[0]); clf_pred_log.append(pred_log[0]);\n",
    "\n",
    "        t_1.add_row([i, c_test[i], pred[0], pred_y[0], pred_dor[0], pred_zero[0], pred_half[0], pred_one[0], pred_log[0]])    \n",
    "    #     print(20*\"#\" + \" Point \" + str(i) + \" \" + 20*\"#\")\n",
    "    #     roc_clf.plot_roc(fpr, tpr, thresholds, roc_auc, cutpoints, clfs=clfs)\n",
    "    # print(t_1)\n",
    "\n",
    "    t_2 = PrettyTable(['point', 'original', 'default', 'youden', 'max dor', 'both zero', 'both half', 'both one', 'both logistic'])\n",
    "\n",
    "    all_pred = []; all_pred_y = []; all_pred_dor = []; all_pred_zero = []; all_pred_half = []; all_pred_one = []; \n",
    "    all_pred_log = []\n",
    "\n",
    "    for i, p in enumerate(p_test):\n",
    "        pred = roc_clf.predict(est, np.array([p]), np.array([c_test[i]]), scaler)\n",
    "        pred_y = roc_clf.predict(est, np.array([p]), np.array([c_test[i]]), scaler, cutpoints, c=0)\n",
    "        pred_dor = roc_clf.predict(est, np.array([p]), np.array([c_test[i]]), scaler, cutpoints, c=1)\n",
    "        pred_zero = roc_clf.predict(est, np.array([p]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='zero')\n",
    "        pred_half = roc_clf.predict(est, np.array([p]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='half')\n",
    "        pred_one = roc_clf.predict(est, np.array([p]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='one')\n",
    "        pred_log = roc_clf.predict(est, np.array([p]), np.array([c_test[i]]), scaler, cutpoints, c=2, mode='logistic')\n",
    "\n",
    "\n",
    "        all_pred.append(pred[0]); all_pred_y.append(pred_y[0]); all_pred_dor.append(pred_dor[0]); all_pred_zero.append(pred_zero[0]);\n",
    "        all_pred_half.append(pred_half[0]); all_pred_one.append(pred_one[0]); all_pred_log.append(pred_log[0]);\n",
    "\n",
    "        t_2.add_row([i, c_test[i], pred[0], pred_y[0], pred_dor[0], pred_zero[0], pred_half[0], pred_one[0], pred_log[0]])   \n",
    "    \n",
    "    \n",
    "    acc_clf_pred.append(accuracy_score(c_test, clf_pred)); acc_clf_pred_y.append(accuracy_score(c_test, clf_pred_y)); \n",
    "    acc_clf_pred_dor.append(accuracy_score(c_test, clf_pred_dor)); acc_clf_pred_zero.append(accuracy_score(c_test, clf_pred_zero)); \n",
    "    acc_clf_pred_half.append(accuracy_score(c_test, clf_pred_half)); acc_clf_pred_one.append(accuracy_score(c_test, clf_pred_one)); \n",
    "    acc_clf_pred_log.append(accuracy_score(c_test, clf_pred_log))\n",
    "    \n",
    "    acc_all_pred.append(accuracy_score(c_test, all_pred)); acc_all_pred_y.append(accuracy_score(c_test, all_pred_y)); \n",
    "    acc_all_pred_dor.append(accuracy_score(c_test, all_pred_dor)); acc_all_pred_zero.append(accuracy_score(c_test, all_pred_zero)); \n",
    "    acc_all_pred_half.append(accuracy_score(c_test, all_pred_half)); acc_all_pred_one.append(accuracy_score(c_test, all_pred_one)); \n",
    "    acc_all_pred_log.append(accuracy_score(c_test, all_pred_log))\n",
    "                                                                                            \n",
    "t_3 = PrettyTable()\n",
    "t_3.add_column('With all clf mean', [np.mean(acc_all_pred), np.mean(acc_all_pred_y),\n",
    "                                     np.mean(acc_all_pred_dor), np.mean(acc_all_pred_zero), \n",
    "                                     np.mean(acc_all_pred_half), np.mean(acc_all_pred_one),\n",
    "                                     np.mean(acc_all_pred_log)])\n",
    "                                                                                            \n",
    "t_3.add_column('With all clf std', [np.std(acc_all_pred), np.std(acc_all_pred_y),\n",
    "                                    np.std(acc_all_pred_dor), np.std(acc_all_pred_zero), \n",
    "                                    np.std(acc_all_pred_half), np.std(acc_all_pred_one),\n",
    "                                    np.std(acc_all_pred_log)])\n",
    "\n",
    "t_3.add_column('With filtered clf mean', [np.mean(acc_clf_pred), np.mean(acc_clf_pred_y),\n",
    "                                          np.mean(acc_clf_pred_dor), np.mean(acc_clf_pred_zero), \n",
    "                                          np.mean(acc_clf_pred_half), np.mean(acc_clf_pred_one),\n",
    "                                          np.mean(acc_clf_pred_log)])\n",
    "\n",
    "t_3.add_column('With filtered clf std', [np.std(acc_clf_pred), np.std(acc_clf_pred_y),\n",
    "                                         np.std(acc_clf_pred_dor), np.std(acc_clf_pred_zero), \n",
    "                                         np.std(acc_clf_pred_half), np.std(acc_clf_pred_one),\n",
    "                                         np.std(acc_clf_pred_log)])\n",
    "\n",
    "# print(t_2)\n",
    "\n",
    "print(t_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/gmatos/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/home/gmatos/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.74it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n",
      "100%|██████████| 10/10 [00:15<00:00,  1.47s/it]\n",
      "100%|██████████| 10/10 [01:18<00:00,  7.98s/it]\n",
      "100%|██████████| 10/10 [04:52<00:00, 29.56s/it]\n",
      "100%|██████████| 10/10 [00:20<00:00,  2.03s/it]\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean acc</th>\n",
       "      <th>std</th>\n",
       "      <th>mean acc yoden</th>\n",
       "      <th>std yoden</th>\n",
       "      <th>mean acc max dor</th>\n",
       "      <th>std max dor</th>\n",
       "      <th>mean acc both zero</th>\n",
       "      <th>std both zero</th>\n",
       "      <th>mean acc both half</th>\n",
       "      <th>std both half</th>\n",
       "      <th>mean acc both one</th>\n",
       "      <th>std both one</th>\n",
       "      <th>mean acc both logistic</th>\n",
       "      <th>std both logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.07151145984308312</td>\n",
       "      <td>0.48500000000000004</td>\n",
       "      <td>0.07243771270700244</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.08491826135237998</td>\n",
       "      <td>0.4466666666666666</td>\n",
       "      <td>0.07408703590297624</td>\n",
       "      <td>0.4883333333333334</td>\n",
       "      <td>0.06710274046399134</td>\n",
       "      <td>0.4566666666666667</td>\n",
       "      <td>0.07118052168020873</td>\n",
       "      <td>0.49833333333333335</td>\n",
       "      <td>0.06808899405271833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>0.5138728323699422</td>\n",
       "      <td>0.021269791321357343</td>\n",
       "      <td>0.49479768786127176</td>\n",
       "      <td>0.04319431605148997</td>\n",
       "      <td>0.43641618497109824</td>\n",
       "      <td>0.09695659531936453</td>\n",
       "      <td>0.47485549132947974</td>\n",
       "      <td>0.07022645622458923</td>\n",
       "      <td>0.4765895953757225</td>\n",
       "      <td>0.06370784015375477</td>\n",
       "      <td>0.4586705202312139</td>\n",
       "      <td>0.06483336046838421</td>\n",
       "      <td>0.4791907514450867</td>\n",
       "      <td>0.06080089614938592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red wine quality</td>\n",
       "      <td>0.43125</td>\n",
       "      <td>0.018750000000000006</td>\n",
       "      <td>0.12000000000000002</td>\n",
       "      <td>0.07236517636266769</td>\n",
       "      <td>0.373125</td>\n",
       "      <td>0.06806763639939321</td>\n",
       "      <td>0.3784374999999999</td>\n",
       "      <td>0.09614086751350852</td>\n",
       "      <td>0.37031249999999993</td>\n",
       "      <td>0.11571997788303451</td>\n",
       "      <td>0.34531249999999997</td>\n",
       "      <td>0.1111046276320208</td>\n",
       "      <td>0.24718750000000003</td>\n",
       "      <td>0.07269169162462792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white wine quality</td>\n",
       "      <td>0.32010204081632654</td>\n",
       "      <td>0.02753230656954784</td>\n",
       "      <td>0.23836734693877554</td>\n",
       "      <td>0.0668973864078778</td>\n",
       "      <td>0.3248979591836735</td>\n",
       "      <td>0.06989341561279211</td>\n",
       "      <td>0.3510204081632653</td>\n",
       "      <td>0.12092159644357982</td>\n",
       "      <td>0.35959183673469386</td>\n",
       "      <td>0.09813462181276303</td>\n",
       "      <td>0.34989795918367345</td>\n",
       "      <td>0.08600467089201404</td>\n",
       "      <td>0.3018367346938775</td>\n",
       "      <td>0.10003622833966114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>0.22649880095923264</td>\n",
       "      <td>0.00946331104190678</td>\n",
       "      <td>0.1804556354916067</td>\n",
       "      <td>0.01645134620385161</td>\n",
       "      <td>0.11235011990407676</td>\n",
       "      <td>0.028732229395647076</td>\n",
       "      <td>0.1922062350119904</td>\n",
       "      <td>0.018089627281554187</td>\n",
       "      <td>0.18441247002398084</td>\n",
       "      <td>0.02047377471318129</td>\n",
       "      <td>0.16330935251798562</td>\n",
       "      <td>0.021561406995672924</td>\n",
       "      <td>0.14112709832134293</td>\n",
       "      <td>0.02174896019669739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>synth8</td>\n",
       "      <td>0.7729166666666667</td>\n",
       "      <td>0.014523687548277828</td>\n",
       "      <td>0.6879166666666667</td>\n",
       "      <td>0.015750881809529837</td>\n",
       "      <td>0.6585416666666667</td>\n",
       "      <td>0.032933144609783145</td>\n",
       "      <td>0.6785416666666667</td>\n",
       "      <td>0.039020672049853544</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.02987531961707226</td>\n",
       "      <td>0.6733333333333335</td>\n",
       "      <td>0.020086617988656585</td>\n",
       "      <td>0.7235416666666666</td>\n",
       "      <td>0.027196079425371406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unbalanced synth8</td>\n",
       "      <td>0.8706250000000001</td>\n",
       "      <td>0.015194057226429036</td>\n",
       "      <td>0.8117187500000002</td>\n",
       "      <td>0.024973130091410233</td>\n",
       "      <td>0.78515625</td>\n",
       "      <td>0.04916415623004731</td>\n",
       "      <td>0.81609375</td>\n",
       "      <td>0.020694131301228866</td>\n",
       "      <td>0.8198437500000001</td>\n",
       "      <td>0.028692622772456693</td>\n",
       "      <td>0.82109375</td>\n",
       "      <td>0.030906313195081987</td>\n",
       "      <td>0.8345312500000001</td>\n",
       "      <td>0.04013800655628653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset             mean acc                   std  \\\n",
       "0               heart                0.495   0.07151145984308312   \n",
       "1                 car   0.5138728323699422  0.021269791321357343   \n",
       "2    red wine quality              0.43125  0.018750000000000006   \n",
       "3  white wine quality  0.32010204081632654   0.02753230656954784   \n",
       "4             abalone  0.22649880095923264   0.00946331104190678   \n",
       "5              synth8   0.7729166666666667  0.014523687548277828   \n",
       "6   unbalanced synth8   0.8706250000000001  0.015194057226429036   \n",
       "\n",
       "        mean acc yoden             std yoden     mean acc max dor  \\\n",
       "0  0.48500000000000004   0.07243771270700244                 0.43   \n",
       "1  0.49479768786127176   0.04319431605148997  0.43641618497109824   \n",
       "2  0.12000000000000002   0.07236517636266769             0.373125   \n",
       "3  0.23836734693877554    0.0668973864078778   0.3248979591836735   \n",
       "4   0.1804556354916067   0.01645134620385161  0.11235011990407676   \n",
       "5   0.6879166666666667  0.015750881809529837   0.6585416666666667   \n",
       "6   0.8117187500000002  0.024973130091410233           0.78515625   \n",
       "\n",
       "            std max dor   mean acc both zero         std both zero  \\\n",
       "0   0.08491826135237998   0.4466666666666666   0.07408703590297624   \n",
       "1   0.09695659531936453  0.47485549132947974   0.07022645622458923   \n",
       "2   0.06806763639939321   0.3784374999999999   0.09614086751350852   \n",
       "3   0.06989341561279211   0.3510204081632653   0.12092159644357982   \n",
       "4  0.028732229395647076   0.1922062350119904  0.018089627281554187   \n",
       "5  0.032933144609783145   0.6785416666666667  0.039020672049853544   \n",
       "6   0.04916415623004731           0.81609375  0.020694131301228866   \n",
       "\n",
       "    mean acc both half         std both half    mean acc both one  \\\n",
       "0   0.4883333333333334   0.06710274046399134   0.4566666666666667   \n",
       "1   0.4765895953757225   0.06370784015375477   0.4586705202312139   \n",
       "2  0.37031249999999993   0.11571997788303451  0.34531249999999997   \n",
       "3  0.35959183673469386   0.09813462181276303  0.34989795918367345   \n",
       "4  0.18441247002398084   0.02047377471318129  0.16330935251798562   \n",
       "5               0.6925   0.02987531961707226   0.6733333333333335   \n",
       "6   0.8198437500000001  0.028692622772456693           0.82109375   \n",
       "\n",
       "           std both one mean acc both logistic     std both logistic  \n",
       "0   0.07118052168020873    0.49833333333333335   0.06808899405271833  \n",
       "1   0.06483336046838421     0.4791907514450867   0.06080089614938592  \n",
       "2    0.1111046276320208    0.24718750000000003   0.07269169162462792  \n",
       "3   0.08600467089201404     0.3018367346938775   0.10003622833966114  \n",
       "4  0.021561406995672924    0.14112709832134293   0.02174896019669739  \n",
       "5  0.020086617988656585     0.7235416666666666  0.027196079425371406  \n",
       "6  0.030906313195081987     0.8345312500000001   0.04013800655628653  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [heart_data(), load_car(), wine_quality_red(), wine_quality_white(), load_abalone(), \n",
    "            load_mat('data/synth8.mat'), load_mat('data/synth8_unbalanced.mat')]\n",
    "\n",
    "cols = ['dataset', 'mean acc', 'std', 'mean acc yoden', 'std yoden', 'mean acc max dor', 'std max dor',\n",
    "        'mean acc both zero', 'std both zero', 'mean acc both half', 'std both half',\n",
    "        'mean acc both one', 'std both one', 'mean acc both logistic', 'std both logistic']\n",
    "names = [['heart'], ['car'], ['red wine quality'], ['white wine quality'], ['abalone'], ['synth8'],\n",
    "         ['unbalanced synth8']]\n",
    "\n",
    "d_rows = []\n",
    "\n",
    "times = 10\n",
    "for d in datasets:\n",
    "    d_rows.append(apply(d, times).ravel())\n",
    "d_rows = np.asarray(d_rows)\n",
    "d_rows = np.concatenate((names, d_rows), axis=1)\n",
    "df = pd.DataFrame(data=np.asarray(d_rows), columns=cols)\n",
    "df\n",
    "# data = heart_data()\n",
    "# data = load_adult()\n",
    "# data = wine_quality_red()\n",
    "# data = wine_quality_white()\n",
    "# data = load_abalone()\n",
    "# data = load_mat('data/synth8.mat')\n",
    "# data = load_mat('data/synth8_unbalanced.mat')\n",
    "\n",
    "# data = heart_data()\n",
    "# apply(data).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/gmatos/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/home/gmatos/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.59it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n",
      "100%|██████████| 10/10 [01:19<00:00,  8.04s/it]\n",
      "100%|██████████| 10/10 [04:52<00:00, 28.85s/it]\n",
      "100%|██████████| 10/10 [00:20<00:00,  2.07s/it]\n",
      "100%|██████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean acc</th>\n",
       "      <th>std</th>\n",
       "      <th>mean acc yoden</th>\n",
       "      <th>std yoden</th>\n",
       "      <th>mean acc max dor</th>\n",
       "      <th>std max dor</th>\n",
       "      <th>mean acc both zero</th>\n",
       "      <th>std both zero</th>\n",
       "      <th>mean acc both half</th>\n",
       "      <th>std both half</th>\n",
       "      <th>mean acc both one</th>\n",
       "      <th>std both one</th>\n",
       "      <th>mean acc both logistic</th>\n",
       "      <th>std both logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.044876373392787536</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.04533823502911815</td>\n",
       "      <td>0.4366666666666667</td>\n",
       "      <td>0.13055437351710758</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.10796089827134432</td>\n",
       "      <td>0.45999999999999996</td>\n",
       "      <td>0.09666666666666666</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.11542193128787191</td>\n",
       "      <td>0.5466666666666666</td>\n",
       "      <td>0.050990195135927854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>0.5242774566473989</td>\n",
       "      <td>0.01896094736052801</td>\n",
       "      <td>0.47572254335260117</td>\n",
       "      <td>0.04044590909719285</td>\n",
       "      <td>0.39768786127167627</td>\n",
       "      <td>0.11719430444844665</td>\n",
       "      <td>0.4505780346820808</td>\n",
       "      <td>0.06544121056205783</td>\n",
       "      <td>0.4436416184971098</td>\n",
       "      <td>0.05986567096362619</td>\n",
       "      <td>0.427456647398844</td>\n",
       "      <td>0.06458034119174333</td>\n",
       "      <td>0.44450867052023124</td>\n",
       "      <td>0.05618842017054451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red wine quality</td>\n",
       "      <td>0.4328125</td>\n",
       "      <td>0.016901021603737448</td>\n",
       "      <td>0.108125</td>\n",
       "      <td>0.05957531997396238</td>\n",
       "      <td>0.4065625</td>\n",
       "      <td>0.045338354692798455</td>\n",
       "      <td>0.39656250000000004</td>\n",
       "      <td>0.0839857921392065</td>\n",
       "      <td>0.4078125</td>\n",
       "      <td>0.10748591840911068</td>\n",
       "      <td>0.37531250000000005</td>\n",
       "      <td>0.12757082897845418</td>\n",
       "      <td>0.2671875</td>\n",
       "      <td>0.10152403117612106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white wine quality</td>\n",
       "      <td>0.333265306122449</td>\n",
       "      <td>0.01622545241657221</td>\n",
       "      <td>0.22418367346938775</td>\n",
       "      <td>0.0632686799627054</td>\n",
       "      <td>0.2942857142857143</td>\n",
       "      <td>0.057097649756040515</td>\n",
       "      <td>0.305204081632653</td>\n",
       "      <td>0.061141866017415815</td>\n",
       "      <td>0.29969387755102045</td>\n",
       "      <td>0.06582708344305488</td>\n",
       "      <td>0.29387755102040813</td>\n",
       "      <td>0.05748802457552357</td>\n",
       "      <td>0.24826530612244904</td>\n",
       "      <td>0.0698410314879462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>0.2252997601918465</td>\n",
       "      <td>0.011729168534972658</td>\n",
       "      <td>0.18273381294964028</td>\n",
       "      <td>0.0202932115089113</td>\n",
       "      <td>0.09136690647482015</td>\n",
       "      <td>0.014800262948881987</td>\n",
       "      <td>0.19352517985611511</td>\n",
       "      <td>0.01939483189025971</td>\n",
       "      <td>0.18956834532374098</td>\n",
       "      <td>0.01837664447530738</td>\n",
       "      <td>0.1695443645083933</td>\n",
       "      <td>0.017076967437294893</td>\n",
       "      <td>0.13501199040767387</td>\n",
       "      <td>0.016873703292328332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>synth8</td>\n",
       "      <td>0.77375</td>\n",
       "      <td>0.013149778198382929</td>\n",
       "      <td>0.6864583333333333</td>\n",
       "      <td>0.0375028934068945</td>\n",
       "      <td>0.6389583333333333</td>\n",
       "      <td>0.03536822667781543</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.026173831290899018</td>\n",
       "      <td>0.6954166666666668</td>\n",
       "      <td>0.029386079470842423</td>\n",
       "      <td>0.6702083333333333</td>\n",
       "      <td>0.030434498197860208</td>\n",
       "      <td>0.6979166666666667</td>\n",
       "      <td>0.04327118941435899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unbalanced synth8</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.08349658488525144</td>\n",
       "      <td>0.8246874999999999</td>\n",
       "      <td>0.027606328531697227</td>\n",
       "      <td>0.8109375</td>\n",
       "      <td>0.04207740263490606</td>\n",
       "      <td>0.8284374999999999</td>\n",
       "      <td>0.024494897427831792</td>\n",
       "      <td>0.8403124999999999</td>\n",
       "      <td>0.029858062667393548</td>\n",
       "      <td>0.8426562499999999</td>\n",
       "      <td>0.030888929676544313</td>\n",
       "      <td>0.84828125</td>\n",
       "      <td>0.03631896725971843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset            mean acc                   std  \\\n",
       "0               heart               0.525  0.044876373392787536   \n",
       "1                 car  0.5242774566473989   0.01896094736052801   \n",
       "2    red wine quality           0.4328125  0.016901021603737448   \n",
       "3  white wine quality   0.333265306122449   0.01622545241657221   \n",
       "4             abalone  0.2252997601918465  0.011729168534972658   \n",
       "5              synth8             0.77375  0.013149778198382929   \n",
       "6   unbalanced synth8            0.840625   0.08349658488525144   \n",
       "\n",
       "        mean acc yoden             std yoden     mean acc max dor  \\\n",
       "0                  0.5   0.04533823502911815   0.4366666666666667   \n",
       "1  0.47572254335260117   0.04044590909719285  0.39768786127167627   \n",
       "2             0.108125   0.05957531997396238            0.4065625   \n",
       "3  0.22418367346938775    0.0632686799627054   0.2942857142857143   \n",
       "4  0.18273381294964028    0.0202932115089113  0.09136690647482015   \n",
       "5   0.6864583333333333    0.0375028934068945   0.6389583333333333   \n",
       "6   0.8246874999999999  0.027606328531697227            0.8109375   \n",
       "\n",
       "            std max dor   mean acc both zero         std both zero  \\\n",
       "0   0.13055437351710758                 0.43   0.10796089827134432   \n",
       "1   0.11719430444844665   0.4505780346820808   0.06544121056205783   \n",
       "2  0.045338354692798455  0.39656250000000004    0.0839857921392065   \n",
       "3  0.057097649756040515    0.305204081632653  0.061141866017415815   \n",
       "4  0.014800262948881987  0.19352517985611511   0.01939483189025971   \n",
       "5   0.03536822667781543                 0.67  0.026173831290899018   \n",
       "6   0.04207740263490606   0.8284374999999999  0.024494897427831792   \n",
       "\n",
       "    mean acc both half         std both half    mean acc both one  \\\n",
       "0  0.45999999999999996   0.09666666666666666                 0.43   \n",
       "1   0.4436416184971098   0.05986567096362619    0.427456647398844   \n",
       "2            0.4078125   0.10748591840911068  0.37531250000000005   \n",
       "3  0.29969387755102045   0.06582708344305488  0.29387755102040813   \n",
       "4  0.18956834532374098   0.01837664447530738   0.1695443645083933   \n",
       "5   0.6954166666666668  0.029386079470842423   0.6702083333333333   \n",
       "6   0.8403124999999999  0.029858062667393548   0.8426562499999999   \n",
       "\n",
       "           std both one mean acc both logistic     std both logistic  \n",
       "0   0.11542193128787191     0.5466666666666666  0.050990195135927854  \n",
       "1   0.06458034119174333    0.44450867052023124   0.05618842017054451  \n",
       "2   0.12757082897845418              0.2671875   0.10152403117612106  \n",
       "3   0.05748802457552357    0.24826530612244904    0.0698410314879462  \n",
       "4  0.017076967437294893    0.13501199040767387  0.016873703292328332  \n",
       "5  0.030434498197860208     0.6979166666666667   0.04327118941435899  \n",
       "6  0.030888929676544313             0.84828125   0.03631896725971843  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [heart_data(), load_car(), wine_quality_red(), wine_quality_white(), load_abalone(), \n",
    "            load_mat('data/synth8.mat'), load_mat('data/synth8_unbalanced.mat')]\n",
    "\n",
    "cols = ['dataset', 'mean acc', 'std', 'mean acc yoden', 'std yoden', 'mean acc max dor', 'std max dor',\n",
    "        'mean acc both zero', 'std both zero', 'mean acc both half', 'std both half',\n",
    "        'mean acc both one', 'std both one', 'mean acc both logistic', 'std both logistic']\n",
    "names = [['heart'], ['car'], ['red wine quality'], ['white wine quality'], ['abalone'], ['synth8'],\n",
    "         ['unbalanced synth8']]\n",
    "\n",
    "d_rows = []\n",
    "\n",
    "times = 10\n",
    "for d in datasets:\n",
    "    d_rows.append(apply(d, times).ravel())\n",
    "d_rows = np.asarray(d_rows)\n",
    "d_rows = np.concatenate((names, d_rows), axis=1)\n",
    "df = pd.DataFrame(data=np.asarray(d_rows), columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('precision', 2)\n",
    "cat_columns = df.select_dtypes(['object']).columns\n",
    "for c in cat_columns:\n",
    "    try:\n",
    "        df[c] = df[c].astype('float64')\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean acc</th>\n",
       "      <th>std</th>\n",
       "      <th>mean acc yoden</th>\n",
       "      <th>std yoden</th>\n",
       "      <th>mean acc max dor</th>\n",
       "      <th>std max dor</th>\n",
       "      <th>mean acc both zero</th>\n",
       "      <th>std both zero</th>\n",
       "      <th>mean acc both half</th>\n",
       "      <th>std both half</th>\n",
       "      <th>mean acc both one</th>\n",
       "      <th>std both one</th>\n",
       "      <th>mean acc both logistic</th>\n",
       "      <th>std both logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red wine quality</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white wine quality</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>synth8</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unbalanced synth8</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset  mean acc   std  mean acc yoden  std yoden  \\\n",
       "0               heart      0.53  0.04            0.50       0.05   \n",
       "1                 car      0.52  0.02            0.48       0.04   \n",
       "2    red wine quality      0.43  0.02            0.11       0.06   \n",
       "3  white wine quality      0.33  0.02            0.22       0.06   \n",
       "4             abalone      0.23  0.01            0.18       0.02   \n",
       "5              synth8      0.77  0.01            0.69       0.04   \n",
       "6   unbalanced synth8      0.84  0.08            0.82       0.03   \n",
       "\n",
       "   mean acc max dor  std max dor  mean acc both zero  std both zero  \\\n",
       "0              0.44         0.13                0.43           0.11   \n",
       "1              0.40         0.12                0.45           0.07   \n",
       "2              0.41         0.05                0.40           0.08   \n",
       "3              0.29         0.06                0.31           0.06   \n",
       "4              0.09         0.01                0.19           0.02   \n",
       "5              0.64         0.04                0.67           0.03   \n",
       "6              0.81         0.04                0.83           0.02   \n",
       "\n",
       "   mean acc both half  std both half  mean acc both one  std both one  \\\n",
       "0                0.46           0.10               0.43          0.12   \n",
       "1                0.44           0.06               0.43          0.06   \n",
       "2                0.41           0.11               0.38          0.13   \n",
       "3                0.30           0.07               0.29          0.06   \n",
       "4                0.19           0.02               0.17          0.02   \n",
       "5                0.70           0.03               0.67          0.03   \n",
       "6                0.84           0.03               0.84          0.03   \n",
       "\n",
       "   mean acc both logistic  std both logistic  \n",
       "0                    0.55               0.05  \n",
       "1                    0.44               0.06  \n",
       "2                    0.27               0.10  \n",
       "3                    0.25               0.07  \n",
       "4                    0.14               0.02  \n",
       "5                    0.70               0.04  \n",
       "6                    0.85               0.04  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
